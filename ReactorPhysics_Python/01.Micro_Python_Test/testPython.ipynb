{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numba\n",
    "import time\n",
    "from numba import jit, prange\n",
    "from functools import lru_cache\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse import find\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[         nan,          nan,          nan, ..., 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00],\n",
       "       [1.001000e+03, 9.991673e-01, 0.000000e+00, ..., 1.000000e+00,\n",
       "        4.510000e+02, 1.000000e+00],\n",
       "       [2.936000e+02, 0.000000e+00, 4.210000e+02, ..., 1.000000e+00,\n",
       "        4.510000e+02, 2.000000e+00],\n",
       "       ...,\n",
       "       [         nan,          nan,          nan, ..., 6.000000e+00,\n",
       "        0.000000e+00, 9.999900e+04],\n",
       "       [         nan,          nan,          nan, ..., 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00],\n",
       "       [         nan,          nan,          nan, ..., 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV data file into a NumPy array object\n",
    "datatest = np.genfromtxt('H_001.CSV', delimiter=';', missing_values='', filling_values=np.nan)\n",
    "\n",
    "# Convert the NumPy array to a float type\n",
    "mm = datatest.astype(np.float64)\n",
    "mm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "788197"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(f\"Import data from {nameOnly}.CSV. \", end=\"\")\n",
    "mmm = np.genfromtxt('U_235.CSV', delimiter=';') # load CSV file into matrix m\n",
    "print(\"Done.\")\n",
    "mmm.shape[0] # number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Read the CSV data file into a Pandas DataFrame object\\ndata = pd.read_csv(\\'H_001.CSV\\', delimiter=\\';\\', header=None)\\ndf = data.replace(r\\'^\\\\s*$\\', np.nan, regex=True).astype(float)   # df contains empty cells, \\n                                                                # replace them with \"NaN\"\\n# Print the updated DataFrame\\nprint(df.head(), \"\\n\", df.tail())   # First and last 5 rows.'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Read the CSV data file into a Pandas DataFrame object\n",
    "data = pd.read_csv('H_001.CSV', delimiter=';', header=None)\n",
    "df = data.replace(r'^\\s*$', np.nan, regex=True).astype(float)   # df contains empty cells, \n",
    "                                                                # replace them with \"NaN\"\n",
    "# Print the updated DataFrame\n",
    "print(df.head(), \"\\n\", df.tail())   # First and last 5 rows.\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Start of extractNwords()\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=======================================================\n",
    "*The purpose of this code is not 100% understood, but \n",
    "this is what I have gathered.*\n",
    "\n",
    "This function reads n 'words' from a specific row of a \n",
    "given matrix and returns them in a vector, along with \n",
    "the row number where the last word was read.\n",
    "-------------------------------------------------------\n",
    "INPUT:\n",
    "n - integer; the total number of words that need to be \n",
    "    extracted from the m matrix (whatever that means);\n",
    "iRow - integer; the index of the starting row of \n",
    "       the \"m\" matrix;\n",
    "m - 2D NumPy array; essentially a matrix containing \n",
    "    the data to be extracted.\n",
    "-------------------------------------------------------\n",
    "NOTE: Why \"m\" is a NumPy array, not a Pandas DataFrame?\n",
    "-------------------------------------------------------\n",
    "NumPy is usually much more forgiving if you are trying \n",
    "to access an element in an array. Essentially:\n",
    "\n",
    "        a[x,y] = a[x][y].\n",
    "\n",
    "For a Pandas DF, you would have to use .iloc[]\n",
    "which gets very bothersome, very quicly. Also,\n",
    "NumPy is just faster. Simple as that.\n",
    "-------------------------------------------------------\n",
    "OUTPUT:\n",
    "a - 1D NumPy array;\n",
    "iRowNew - integer; updated row number\n",
    "=======================================================\n",
    "\"\"\"\n",
    "\n",
    "#@jit(nopython=True)\n",
    "def extractNwordsOLD(n, iRow, m):\n",
    "    k = 0   # counter for filling vector a\n",
    "    iRowNew = iRow\n",
    "    #a = np.empty((1,n), dtype=np.float64)\n",
    "    a = []\n",
    "    for ii in range(int(n/6)):  # read lines with 6 words each\n",
    "        for jj in range(6):\n",
    "            #a[0][k] = m[iRowNew][jj]\n",
    "            a.append(m[iRowNew][jj])\n",
    "            k += 1\n",
    "        iRowNew += 1\n",
    "\n",
    "    if (int(n - int(n/6)*6)) == 0:   # check if there's a partial line with less than 6 words\n",
    "        iRowNew -= 1    # if yes, stay on the same row for next call to extractNwords()\n",
    "\n",
    "    for jj in range(int(n-int(n/6)*6)):  # read the last line with less than 6 words\n",
    "        #a[0][k] = m[iRowNew][jj]\n",
    "        a.append(m[iRowNew][jj])\n",
    "        k += 1\n",
    "\n",
    "    a = np.array(a)\n",
    "    return a, iRowNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def extractNwords(n, iRow, m):\n",
    "    a = np.empty(n, dtype=np.float64)  # Use a Numpy array directly instead of a list\n",
    "    k = 0  # counter for filling vector a\n",
    "    iRowNew = iRow\n",
    "\n",
    "    for ii in range(int(n / 6)):  # read lines with 6 words each\n",
    "        for jj in range(6):\n",
    "            a[k] = m[iRowNew, jj]  # Access Numpy array elements directly\n",
    "            k += 1\n",
    "        iRowNew += 1\n",
    "\n",
    "    if (n - int(n / 6) * 6) == 0:  # check if there's a partial line with less than 6 words\n",
    "        iRowNew -= 1  # if yes, stay on the same row for the next call to extractNwords()\n",
    "\n",
    "    for jj in range(n - int(n / 6) * 6):  # read the last line with less than 6 words\n",
    "        a[k] = m[iRowNew, jj]  # Access Numpy array elements directly\n",
    "        k += 1\n",
    "\n",
    "    return a, iRowNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True, parallel=True)\n",
    "def extractNwordsPARA(n, iRow, m):\n",
    "    a = np.empty(n, dtype=np.float64)  # Use a Numpy array directly instead of a list\n",
    "\n",
    "    for ii in prange(int(n / 6)):  # Use prange for parallel iteration\n",
    "        for jj in range(6):\n",
    "            a[ii * 6 + jj] = m[iRow + ii, jj]  # Access Numpy array elements directly\n",
    "\n",
    "    if (n - int(n / 6) * 6) == 0:  # check if there's a partial line with less than 6 words\n",
    "        iRowNew = iRow + int(n / 6) - 1  # if yes, stay on the same row for the next call to extractNwords()\n",
    "    else:\n",
    "        for jj in range(n - int(n / 6) * 6):  # read the last line with less than 6 words\n",
    "            a[int(n / 6) * 6 + jj] = m[iRow + int(n / 6), jj]  # Access Numpy array elements directly\n",
    "        iRowNew = iRow + int(n / 6)  # Update iRowNew accordingly\n",
    "\n",
    "    return a, iRowNew\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference found at index 4: cba[0][4] = nan, abc[0][4] = nan\n",
      "Difference found at index 5: cba[0][5] = nan, abc[0][5] = nan\n",
      "Difference found at index 33: cba[0][33] = nan, abc[0][33] = nan\n",
      "Difference found at index 34: cba[0][34] = nan, abc[0][34] = nan\n",
      "Difference found at index 35: cba[0][35] = nan, abc[0][35] = nan\n",
      "Difference found at index 63: cba[0][63] = nan, abc[0][63] = nan\n",
      "Difference found at index 64: cba[0][64] = nan, abc[0][64] = nan\n",
      "Difference found at index 65: cba[0][65] = nan, abc[0][65] = nan\n"
     ]
    }
   ],
   "source": [
    "abc = extractNwordsOLD(6 * 6 * 2, 338582, mmm)\n",
    "cba = extractNwordsPARA(6 * 6 * 2, 338582, mmm)\n",
    "for i in range(len(cba[0])):\n",
    "    if cba[0][i] != abc[0][i]:\n",
    "        print(f\"Difference found at index {i}: cba[0][{i}] = {cba[0][i]}, abc[0][{i}] = {abc[0][i]}\")\n",
    "    #else:\n",
    "    #    print(\"No differences were found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 10000\n",
      "Execution time of extractNwordsOLD(): 0.381559 seconds\n",
      "Execution time of extractNwords(): 0.009431 seconds\n",
      "Speedup: 40.46x\n"
     ]
    }
   ],
   "source": [
    "# Set the number of iterations\n",
    "num_iterations = 10000\n",
    "print(f\"Number of iterations: {num_iterations}\")\n",
    "\n",
    "# Create a function to run the benchmark\n",
    "def benchmark(func, *args, **kwargs):\n",
    "    start_time = time.time()\n",
    "    for _ in range(num_iterations):\n",
    "        func(*args, **kwargs)\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time\n",
    "\n",
    "# Run the benchmark for extractNwordsOLD()\n",
    "old_time = benchmark(extractNwordsOLD,6 * 6 * 2, 338582, mmm)\n",
    "print(f\"Execution time of extractNwordsOLD(): {old_time:.6f} seconds\")\n",
    "\n",
    "# Run the benchmark for extractNwordsPARA\n",
    "new_time = benchmark(extractNwords, 6 * 6 * 2, 338582, mmm)\n",
    "print(f\"Execution time of extractNwords(): {new_time:.6f} seconds\")\n",
    "\n",
    "# Calculate the speedup\n",
    "speedup = old_time / new_time\n",
    "print(f\"Speedup: {speedup:.2f}x\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Start of extract_mf3()\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "==========================================================\n",
    "In an ENDF type of file, MF 3 refers to the section that \n",
    "provides the cross-sections for outgoing neutrons produced \n",
    "by a particular reaction. Specifically, MF 3 contains the \n",
    "angular distributions and energy distributions of the \n",
    "outgoing neutrons, which are necessary for determining \n",
    "how the neutrons will interact with matter in subsequent \n",
    "calculations. The data in MF 3 is typically provided in \n",
    "tabular form as a function of incident neutron energy and \n",
    "scattering angle. This function extracts this data from\n",
    "the preprocessed CSV file.\n",
    "---\n",
    "This code defines a function called \"extract_mf3\" that \n",
    "takes three inputs: mt, ntt, and m, and returns an output \n",
    "called sig. The purpose of this function is to search the \n",
    "matrix m for cross sections sig from file mf=3 for a \n",
    "specified reaction mt and temperature ntt, and return \n",
    "sig(ng,nSig0), where ng is the number of energy groups \n",
    "and nSig0 is the number of sigma-zeros.\n",
    "----------------------------------------------------------\n",
    "INPUT:\n",
    "mt  - integer; reaction\n",
    "ntt - integer; index for temperature value\n",
    "m - 2D NumPy array;\n",
    "----------------------------------------------------------\n",
    "OUTPUT:\n",
    "sig(nSig0, enGroup)- 2D NumPy array; where \"enGroup\" is \n",
    "the number of energy groups and \"nSig0\" is the the number \n",
    "of sigma-zeros.\n",
    "==========================================================\n",
    "\"\"\"\n",
    "#@njit(parallel=True)\n",
    "#@jit(nopython=True)\n",
    "def extract_mf3OLD(mt, ntt, m):\n",
    "    nRow = m.shape[0]  # number of rows\n",
    "    # ntemp starts from -1 to ensure \n",
    "    # Python indexing\n",
    "    nTemp = -1  # number of temperatures\n",
    "    iRowFound = 0\n",
    "    #sig = []\n",
    "    for iRow in range(nRow):\n",
    "        #if m.iloc[iRow, 7] == 3 and m.iloc[iRow, 8] == mt and m.iloc[iRow, 9] == 1:\n",
    "        if m[iRow, 7] == 3 and m[iRow, 8] == mt and m[iRow, 9] == 1:\n",
    "            # find the row with mf=3 and required mt\n",
    "            nTemp += 1  # number of temperatures\n",
    "            if nTemp == ntt: \n",
    "                iRowFound = iRow + 1\n",
    "                break\n",
    "    if iRowFound > 0:  # there is mf=3 and required mt for this isotope\n",
    "        nSig0 = int(m[iRowFound-1, 3])  # number of sigma-zeros\n",
    "        nLgn = int(m[iRowFound-1, 2])  # number of Legendre components\n",
    "        iRow = iRowFound + 1\n",
    "        enGroup = int(m[2, 2])\n",
    "        sig = np.zeros((nSig0, enGroup))\n",
    "        while m[iRow, 7] == 3 and m[iRow, 8] == mt:\n",
    "            ig = int(m[iRow-1, 5])\n",
    "            a, iRowNew = extractNwords(nSig0 * nLgn * 2, iRow, m)\n",
    "            sig[0:nSig0, ig-1] = a[nSig0*nLgn:(nSig0*nLgn+nSig0)] # Benefits of using NumPy: a[x,y] = a[x][y]\n",
    "            #sig.append(a[nSig0*nLgn:(nSig0*nLgn+nSig0)])\n",
    "            iRow = iRowNew + 2                                       \n",
    "    else:\n",
    "        #sig.append(0)\n",
    "        sig = np.zeros(1)\n",
    "    # Make list into NumPy array\n",
    "    #sig = np.array(sig)\n",
    "    return sig\n",
    "\n",
    "#====================================================\n",
    "# Example to check against MATLAB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def extract_mf3(mt, ntt, m):\n",
    "    nRow = m.shape[0]  # number of rows\n",
    "    nTemp = -1  # number of temperatures\n",
    "    iRowFound = 0\n",
    "\n",
    "    for iRow in range(nRow):\n",
    "        if m[iRow, 7] == 3 and m[iRow, 8] == mt and m[iRow, 9] == 1:\n",
    "            nTemp += 1  # number of temperatures\n",
    "            if nTemp == ntt: \n",
    "                iRowFound = iRow + 1\n",
    "                break\n",
    "\n",
    "    if iRowFound > 0:  # there is mf=3 and required mt for this isotope\n",
    "        nSig0 = int(m[iRowFound-1, 3])  # number of sigma-zeros\n",
    "        nLgn = int(m[iRowFound-1, 2])  # number of Legendre components\n",
    "        iRow = iRowFound + 1\n",
    "        enGroup = int(m[2, 2])\n",
    "        sig = np.zeros((nSig0, enGroup))\n",
    "\n",
    "        while m[iRow, 7] == 3 and m[iRow, 8] == mt:\n",
    "            ig = int(m[iRow-1, 5])\n",
    "            a, iRowNew = extractNwords(nSig0 * nLgn * 2, iRow, m)\n",
    "            sig[0:nSig0, ig-1] = a[nSig0*nLgn:(nSig0*nLgn+nSig0)]\n",
    "            iRow = iRowNew + 2                                       \n",
    "    else:\n",
    "        sig = np.zeros((1, 1))  # Modify the shape to match a 2D array\n",
    "\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True, parallel=True)\n",
    "def extract_mf3PARA(mt, ntt, m):\n",
    "    nRow = m.shape[0]  # number of rows\n",
    "    nTemp = -1  # number of temperatures\n",
    "    iRowFound = 0\n",
    "\n",
    "    for iRow in prange(nRow):\n",
    "        if m[iRow, 7] == 3 and m[iRow, 8] == mt and m[iRow, 9] == 1:\n",
    "            nTemp += 1  # number of temperatures\n",
    "            if nTemp == ntt: \n",
    "                iRowFound = iRow + 1\n",
    "                break\n",
    "\n",
    "    if iRowFound > 0:  # there is mf=3 and required mt for this isotope\n",
    "        nSig0 = int(m[iRowFound-1, 3])  # number of sigma-zeros\n",
    "        nLgn = int(m[iRowFound-1, 2])  # number of Legendre components\n",
    "        iRow = iRowFound + 1\n",
    "        enGroup = int(m[2, 2])\n",
    "        sig = np.zeros((nSig0, enGroup))\n",
    "\n",
    "        while m[iRow, 7] == 3 and m[iRow, 8] == mt:\n",
    "            ig = int(m[iRow-1, 5])\n",
    "            a, iRowNew = extractNwords(nSig0 * nLgn * 2, iRow, m)\n",
    "            sig[0:nSig0, ig-1] = a[nSig0*nLgn:(nSig0*nLgn+nSig0)]\n",
    "            iRow = iRowNew + 2                                       \n",
    "    else:\n",
    "        sig = np.zeros((1, 1))  # Modify the shape to match a 2D array\n",
    "\n",
    "    return sig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 421)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigC= extract_mf3PARA(102, 7, mm)\n",
    "sigC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = extract_mf3OLD(102, 7, mmm)\n",
    "cba = extract_mf3PARA(102, 7, mmm)\n",
    "for i in range(len(cba)):\n",
    "    if cba[i] != abc[i]:\n",
    "        print(f\"Difference found at index {i}: cba[{i}] = {cba[i]}, abc[{i}] = {abc[i]}\")\n",
    "    #else:\n",
    "    #    print(\"No differences were found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 50\n",
      "Execution time of extract_mf3OLD(): 10.160006 seconds\n",
      "Execution time of extract_mf3PARA(): 0.254721 seconds\n",
      "Speedup: 39.89x\n"
     ]
    }
   ],
   "source": [
    "# Set the number of iterations\n",
    "num_iterations = 50\n",
    "print(f\"Number of iterations: {num_iterations}\")\n",
    "\n",
    "# Create a function to run the benchmark\n",
    "def benchmark(func, *args, **kwargs):\n",
    "    start_time = time.time()\n",
    "    for _ in range(num_iterations):\n",
    "        func(*args, **kwargs)\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time\n",
    "\n",
    "# Run the benchmark for extract_mf3OLD()\n",
    "old_time = benchmark(extract_mf3OLD, 16, 3, mm)\n",
    "print(f\"Execution time of extract_mf3OLD(): {old_time:.6f} seconds\")\n",
    "\n",
    "# Run the benchmark for extract_mf3PARA()\n",
    "new_time = benchmark(extract_mf3PARA, 16, 3, mm)\n",
    "print(f\"Execution time of extract_mf3PARA(): {new_time:.6f} seconds\")\n",
    "\n",
    "# Calculate the speedup\n",
    "speedup = old_time / new_time\n",
    "print(f\"Speedup: {speedup:.2f}x\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Start of extract_mf6()\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "==============================================================\n",
    "MF 6 stands for \"Cross Sections\" in an ENDF (Evaluated Nuclear\n",
    "Data File) type of file. This section contains the evaluated \n",
    "cross-section data, such as the neutron-induced reaction cross \n",
    "sections, as a function of incident neutron energy. The cross-\n",
    "section data may be provided in tabular or in resonance format. \n",
    "Additionally, the section may also contain the angular distri-\n",
    "butions, energy-angle distributions, or other related data. \n",
    "This information is essential for the calculation of the neut-\n",
    "ron transport in nuclear reactors and other applications.\n",
    "---\n",
    "This code extracts cross sections from a matrix m that stores \n",
    "nuclear data for different isotopes, reactions, and \n",
    "temperatures. The matrix is in the ENDF format. The function \n",
    "specifically extracts cross sections for a given reaction mt \n",
    "and temperature ntt from the subsection of m that has mf=6 \n",
    "(multiplicity representation) data\n",
    "---\n",
    "In the context of nuclear physics, the \"multiplicity \n",
    "representation\" refers to a way of describing the number of \n",
    "particles emitted in a particular type of nuclear reaction, \n",
    "such as a fission or an (n,xn) reaction.\n",
    "--------------------------------------------------------------\n",
    "MAIN TASKS:\n",
    " 1. Initialize variables (iRow, nTemp, ifrom, ito, sig)\n",
    " 2. Loop through each row of the ENDF file (until the end is \n",
    " reached)\n",
    " 3. If the current row contains the MF/MT we are looking for, \n",
    " extract the data\n",
    " 4. Store the data in a list (sig)\n",
    "--------------------------------------------------------------\n",
    "INPUT:\n",
    "mt  - integer; reaction;\n",
    "ntt - integer; index for temperature value;\n",
    "m - 2D NumPy array; contains the ENDF data\n",
    "--------------------------------------------------------------\n",
    "OUTPUT:\n",
    "ifrom - 1D NumPy array;\n",
    "ito   - 1D NumPy array;\n",
    "sig   - 3D NumPy array;\n",
    "==============================================================\n",
    "\"\n",
    "\"\"\"\n",
    "#@njit(parallel=True)\n",
    "#@jit(nopython=True)\n",
    "def extract_mf6OLD(mt, ntt, m):\n",
    "    iRow = 0 # row number               \n",
    "    nTemp = -1 # number of temperatures; \"-1\" for Python indexing; \"0\" for Matlab indexing\n",
    "    # \"ifrom\" and \"ito\" will be both defined as empty lists\n",
    "    # and bc depending on the CSV file, their sizes can change.\n",
    "    # Later, they will be made into a NumPy arrays, bc it's \n",
    "    # fast way to do scientific computing and can be easily \n",
    "    # converted into other libraries, if need be.\n",
    "    ifrom = [] # index of group 'from'\n",
    "    ito = [] # index of group 'to'\n",
    "    # \"sig\" starts out as a 1D array, but will later be \n",
    "    # reshaped into a 3D array.\n",
    "    sig = []\n",
    "    \n",
    "    while m[iRow,6] != -1: # up to the end\n",
    "        if m[iRow,7] == 6 and m[iRow,8] == mt: # find the row with mf=6 & mt\n",
    "            if m[iRow,9] == 1: # this is the first line of mf=6 & mt: initialize\n",
    "                nonz = 0 # number of nonzeros\n",
    "                nLgn = int(m[iRow,2]) # number of Legendre components\n",
    "                nSig0 = int(m[iRow,3]) # number of sigma-zeros\n",
    "                iRow += 1\n",
    "                nTemp += 1 # temperature index\n",
    "\n",
    "            ng2 = int(m[iRow,2]) # number of secondary positions\n",
    "            ig2lo = int(m[iRow,3]) # index to lowest nonzero group\n",
    "            nw = int(m[iRow,4]) # number of words to be read\n",
    "            ig = int(m[iRow,5]) # current group index\n",
    "            iRow += 1     \n",
    "            a, iRowNew = extractNwords(nw, iRow, m) # extract nw words in vector a\n",
    "            iRow = iRowNew\n",
    "\n",
    "            if nTemp == ntt:\n",
    "                k = nLgn*nSig0 # the first nLgn*nSig0 words are flux -- skip.\n",
    "                for iTo in range(ig2lo, ig2lo+ng2-1):\n",
    "                    nonz += 1\n",
    "                    ifrom.append(ig)\n",
    "                    ito.append(iTo)\n",
    "                    for iSig0 in range(int(nSig0)):\n",
    "                        for iLgn in range(int(nLgn)):\n",
    "                            k += 1\n",
    "                            #print(\"iLgn =\", iLgn, \"iSig0 =\", iSig0, \"nonz-1 =\",nonz-1, \"a[k-1] =\",a[k-1] )                            \n",
    "                            ## NOTE: THIS WORKS, DON'T TOUCH!!!!\n",
    "                            data = np.append((iLgn, iSig0, nonz-1), a[k-1])\n",
    "                            sig.append(data)\n",
    "                            ## NOTE: THIS WORKS, DON'T TOUCH!!!!\n",
    "                    #if nLgn == 1:\n",
    "                    #    sig = np.vstack([sig, np.zeros_like(sig[0]), np.zeros_like(sig[0])])\n",
    "                        #if nLgn == 1:\n",
    "                        #    for i in range(2):\n",
    "                        #        data = np.append((i, iSig0, nonz-1), a[k-1])\n",
    "                        #        sig.append(data)    # makes it an array of arrays\n",
    "        iRow += 1\n",
    "        \n",
    "    if nTemp == -1:\n",
    "        #sigFinal = 0\n",
    "        sigFinal = np.zeros(1)\n",
    "    else:\n",
    "        sig   = np.stack(sig)           # makes the array of arrays into one array\n",
    "        #sigShape = sig.shape[0]         # get the length of the 1D array\n",
    "        z = int(sig.shape[0]/(nLgn*nSig0))  # find how long is the 3rd dimesion of the 3D array\n",
    "        # sig[:, sig.shape[1]-1] - take all the elements from the last column\n",
    "        # containing all the data;\n",
    "        # reshape((nLgn, nSig0, z), order='F') - the 2D shape of the 3D array \n",
    "        # can be defined by the values of \"nLgn\" and \"nSig0\". \"z\" has been\n",
    "        # calculated based on the lengtyh of the 1D array. \"order\" decribes\n",
    "        # the way data is stored in the final (\"sigFinal\" 3D matrix). Specifically,\n",
    "        # \"order='F'\" signifies the Fortran-like inexing order, which Matlab uses,\n",
    "        # bc in Matlab, data is stored row-wise rather than column-wise like in\n",
    "        # C or Python (order = 'C'; the default option for reshape)\n",
    "        sigFinal = sig[:, sig.shape[1]-1].reshape((nLgn, nSig0, z), order='F')\n",
    "        if nLgn == 1:   # Not sure why this is necessary, maybe for discrete ordinate method?\n",
    "            # create two rows of zeros with shape (2, nSig0, sigShape)\n",
    "            rows_of_zeros = np.zeros((2, nSig0, z))\n",
    "            # stack original array and rows of zeros vertically\n",
    "            sigFinal = np.vstack((sigFinal, rows_of_zeros))\n",
    "    \n",
    "    # Convert lists to NumPy arrays for faster processing\n",
    "    # and for (ifrom == 0).all() check to work\n",
    "    ifrom = np.array(ifrom) \n",
    "    ito   = np.array(ito) \n",
    "    # Return the extracted data as well as the indices\n",
    "    return ifrom, ito, sigFinal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def extract_mf6(mt, ntt, m):\n",
    "    iRow = 0  # row number\n",
    "    nTemp = -1  # number of temperatures; \"-1\" for Python indexing; \"0\" for Matlab indexing\n",
    "    ifrom = []  # index of group 'from'\n",
    "    ito = []  # index of group 'to'\n",
    "    sig = []\n",
    "    sig_shape = 0  # length of the 1D array\n",
    "    nLgn = 0  # number of Legendre components\n",
    "    nSig0 = 0  # number of sigma-zeros\n",
    "\n",
    "    while m[iRow, 6] != -1:  # up to the end\n",
    "        if m[iRow, 7] == 6 and m[iRow, 8] == mt:  # find the row with mf=6 & mt\n",
    "            if m[iRow, 9] == 1:  # this is the first line of mf=6 & mt: initialize\n",
    "                nonz = 0  # number of nonzeros\n",
    "                nLgn = int(m[iRow, 2])  # number of Legendre components\n",
    "                nSig0 = int(m[iRow, 3])  # number of sigma-zeros\n",
    "                iRow += 1\n",
    "                nTemp += 1  # temperature index\n",
    "\n",
    "            ng2 = int(m[iRow, 2])  # number of secondary positions\n",
    "            ig2lo = int(m[iRow, 3])  # index to lowest nonzero group\n",
    "            nw = int(m[iRow, 4])  # number of words to be read\n",
    "            ig = int(m[iRow, 5])  # current group index\n",
    "            iRow += 1\n",
    "            a, iRowNew = extractNwords(nw, iRow, m)  # extract nw words in vector a\n",
    "            iRow = iRowNew\n",
    "\n",
    "            if nTemp == ntt:\n",
    "                k = nLgn * nSig0  # the first nLgn*nSig0 words are flux -- skip.\n",
    "                for iTo in range(ig2lo, ig2lo + ng2 - 1):\n",
    "                    nonz += 1\n",
    "                    ifrom.append(ig)\n",
    "                    ito.append(iTo)\n",
    "                    for iSig0 in range(nSig0):\n",
    "                        for iLgn in range(nLgn):\n",
    "                            k += 1\n",
    "                            data = np.append((iLgn, iSig0, nonz - 1), a[k - 1])\n",
    "                            sig.append(data)\n",
    "\n",
    "        iRow += 1\n",
    "\n",
    "    if nTemp == -1:\n",
    "        sigFinal = np.zeros((1, 1, 1))\n",
    "    else:\n",
    "        sig_shape = len(sig) // (nLgn * nSig0)\n",
    "        sigFinal = np.empty((nLgn, nSig0, sig_shape), dtype=np.float64)\n",
    "        idx = 0\n",
    "        for i in range(nLgn):\n",
    "            for j in range(nSig0):\n",
    "                for k in range(sig_shape):\n",
    "                    sigFinal[i, j, k] = sig[idx][3]\n",
    "                    idx += 1\n",
    "\n",
    "        if nLgn == 1:\n",
    "            rows_of_zeros = np.zeros((2, nSig0, sig_shape), dtype=np.float64)\n",
    "            sigFinal = np.vstack((sigFinal, rows_of_zeros))\n",
    "\n",
    "    ifrom = np.array(ifrom)\n",
    "    ito = np.array(ito)\n",
    "    return ifrom, ito, sigFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True, parallel=True)\n",
    "def extract_mf6PARA(mt, ntt, m):\n",
    "    iRow = 0  # row number\n",
    "    nTemp = -1  # number of temperatures; \"-1\" for Python indexing; \"0\" for Matlab indexing\n",
    "    ifrom = np.empty(0, dtype=np.int64)  # index of group 'from'\n",
    "    ito = np.empty(0, dtype=np.int64)  # index of group 'to'\n",
    "    sig = []\n",
    "    sig_shape = 0  # length of the 1D array\n",
    "    nLgn = 0  # number of Legendre components\n",
    "    nSig0 = 0  # number of sigma-zeros\n",
    "\n",
    "    while m[iRow, 6] != -1:  # up to the end\n",
    "        if m[iRow, 7] == 6 and m[iRow, 8] == mt:  # find the row with mf=6 & mt\n",
    "            if m[iRow, 9] == 1:  # this is the first line of mf=6 & mt: initialize\n",
    "                nonz = 0  # number of nonzeros\n",
    "                nLgn = int(m[iRow, 2])  # number of Legendre components\n",
    "                nSig0 = int(m[iRow, 3])  # number of sigma-zeros\n",
    "                iRow += 1\n",
    "                nTemp += 1  # temperature index\n",
    "\n",
    "            ng2 = int(m[iRow, 2])  # number of secondary positions\n",
    "            ig2lo = int(m[iRow, 3])  # index to lowest nonzero group\n",
    "            nw = int(m[iRow, 4])  # number of words to be read\n",
    "            ig = int(m[iRow, 5])  # current group index\n",
    "            iRow += 1\n",
    "            a, iRowNew = extractNwordsPARA(nw, iRow, m)  # extract nw words in vector a\n",
    "            iRow = iRowNew\n",
    "\n",
    "            if nTemp == ntt:\n",
    "                k = nLgn * nSig0  # the first nLgn*nSig0 words are flux -- skip.\n",
    "                for iTo in range(ig2lo, ig2lo + ng2 - 1):\n",
    "                    nonz += 1\n",
    "                    ifrom = np.append(ifrom, ig)\n",
    "                    ito = np.append(ito, iTo)\n",
    "                    for iSig0 in range(nSig0):\n",
    "                        for iLgn in range(nLgn):\n",
    "                            k += 1\n",
    "                            data = np.array([iLgn, iSig0, nonz - 1, a[k - 1]], dtype=np.float64)\n",
    "                            sig.append(data)\n",
    "\n",
    "        iRow += 1\n",
    "\n",
    "    if nTemp == -1:\n",
    "        sigFinal = np.zeros((1, 1, 1))\n",
    "    else:\n",
    "        sig_shape = len(sig) // (nLgn * nSig0)\n",
    "        sigFinal = np.empty((nLgn, nSig0, sig_shape), dtype=np.float64)\n",
    "        idx = 0\n",
    "        for i in range(nLgn):\n",
    "            for j in range(nSig0):\n",
    "                for k in range(sig_shape):\n",
    "                    sigFinal[i, j, k] = sig[idx][3]\n",
    "                    idx += 1\n",
    "\n",
    "        if nLgn == 1:\n",
    "            rows_of_zeros = np.zeros((2, nSig0, sig_shape), dtype=np.float64)\n",
    "            sigFinal = np.vstack((sigFinal, rows_of_zeros))\n",
    "\n",
    "    return ifrom, ito, sigFinal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.125906e-09,  2.360490e-10,  1.125420e-10, ...,\n",
       "          2.307347e-06,  5.875035e-07,  1.182018e-07]],\n",
       "\n",
       "       [[ 0.000000e+00,  5.667266e-09,  6.758465e-04, ...,\n",
       "          7.523968e-03,  4.512612e-05,  1.734396e-05]],\n",
       "\n",
       "       [[ 0.000000e+00,  0.000000e+00,  0.000000e+00, ...,\n",
       "         -1.069373e-06,  3.484839e-07,  3.548485e-04]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.000000e+00,  2.799837e-09,  4.381700e-10, ...,\n",
       "          3.099060e-10,  8.708290e-11,  2.758020e-11]],\n",
       "\n",
       "       [[ 2.348690e-12,  0.000000e+00,  0.000000e+00, ...,\n",
       "          0.000000e+00,  6.451279e-03,  9.198245e-04]],\n",
       "\n",
       "       [[ 9.684704e-05, -1.241829e-05,  0.000000e+00, ...,\n",
       "          3.340205e-08,  1.301783e-08,  3.742131e-09]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ifrom2, ito2, sig2 = extract_mf6PARA(16, 3, mmm)  # Extract mf=6 mt=16 ((n,2n) matrix)\n",
    "sig2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 10\n",
      "Execution time of extract_mf6OLD(): 7.299300 seconds\n",
      "Execution time of extract_mf6(): 0.220924 seconds\n",
      "Speedup: 33.04x\n"
     ]
    }
   ],
   "source": [
    "# Set the number of iterations\n",
    "num_iterations = 10\n",
    "print(f\"Number of iterations: {num_iterations}\")\n",
    "\n",
    "# Create a function to run the benchmark\n",
    "def benchmark(func, *args, **kwargs):\n",
    "    start_time = time.time()\n",
    "    for _ in range(num_iterations):\n",
    "        func(*args, **kwargs)\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time\n",
    "\n",
    "# Run the benchmark for extract_mf6OLD\n",
    "old_time = benchmark(extract_mf6OLD, 16, 3, mmm)\n",
    "print(f\"Execution time of extract_mf6OLD(): {old_time:.6f} seconds\")\n",
    "\n",
    "# Run the benchmark for extract_mf6PARA\n",
    "new_time = benchmark(extract_mf6, 16, 3, mmm)\n",
    "print(f\"Execution time of extract_mf6(): {new_time:.6f} seconds\")\n",
    "\n",
    "# Calculate the speedup\n",
    "speedup = old_time / new_time\n",
    "print(f\"Speedup: {speedup:.2f}x\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#================================\\n# Testing different methods\\n#================================\\nmt = 16\\nntt = 3\\nm = mmm\\n#def extract_mf6(mt, ntt, m):\\niRow = 0 # row number               \\nnTemp = -1 # number of temperatures\\n# \"ifrom\" and \"ito\" will be both defined as empty lists\\n# and bc depending on the CSV file, their sizes can change.\\n# Later, they will be made into a NumPy arrays, bc it\\'s \\n# fast way to do scientific computing and can be easily \\n# converted into other libraries, if need be.\\nifrom = [] # index of group \\'from\\'\\nito = [] # index of group \\'to\\'\\n#sig = np.zeros((7, 6, 4636)) # <-- the best method currently but its basically cheating\\n#sig = np.zeros([7, 6, 4636])\\n\\n# \\nsig = []\\n\\nwhile m[iRow,6] != -1: # up to the end\\n    if m[iRow,7] == 6 and m[iRow,8] == mt: # find the row with mf=6 & mt\\n        if m[iRow,9] == 1: # this is the first line of mf=6 & mt: initialize\\n            nonz = 0 # number of nonzeros\\n            nLgn = int(m[iRow,2]) # number of Legendre components\\n            nSig0 = int(m[iRow,3]) # number of sigma-zeros\\n            print(\"nLgn =\", nLgn)\\n\\n            iRow += 1\\n            nTemp += 1 # temperature index\\n            #print(\"nTemp = \", nTemp)\\n        ng2 = int(m[iRow,2]) # number of secondary positions\\n        ig2lo = int(m[iRow,3]) # index to lowest nonzero group\\n        nw = int(m[iRow,4]) # number of words to be read\\n        ig = int(m[iRow,5]) # current group index\\n        #print(\"ng2 =\", ng2, \"ig2lo =\", ig2lo)\\n        iRow += 1     \\n        a, iRowNew = extractNwords(nw, iRow, m) # extract nw words in vector a\\n        iRow = iRowNew\\n\\n        #sig = np.zeros((nLgn, nSig0, nonz))\\n        #sig = [[[0 for k in range(nonz)] for j in range(nSig0)] for i in range(nLgn)]\\n\\n        if nTemp == ntt:\\n            #print(\"nTemp =\", nTemp,\\n            #      \"ntt =\", ntt,\\n            #      \"count =\", count)\\n            #count += 1\\n            k = nLgn*nSig0 # the first nLgn*nSig0 words are flux -- skip.\\n            \\n            #sig = [[[0 for k in range(nonz)] for j in range(nSig0)] for i in range(nLgn)]\\n            for iTo in range(ig2lo, ig2lo+ng2-1):\\n                nonz += 1\\n                ifrom.append(ig)\\n                ito.append(iTo)\\n                #print(ig2lo)\\n                #sig = np.zeros((nLgn, nSig0, nonz)) # Gives correct dimensions but only saves the last value\\n                # sig = np.empty((nLgn, nSig0, nonz))\\n                #sig = [[[0 for k in range(nonz)] for j in range(nSig0)] for i in range(nLgn)]\\n                #sig = [[[] for _ in range(nSig0)] for _ in range(nLgn)]\\n                for iSig0 in range(int(nSig0)):\\n                    for iLgn in range(int(nLgn)):\\n                        k += 1\\n                        #print(\"iLgn =\", iLgn, \"iSig0 =\", iSig0, \"nonz-1 =\",nonz-1, \"a[k-1] =\",a[k-1] )\\n                        #sig[iLgn][iSig0].append(a[k-1])\\n                        #sig[iLgn][iSig0].insert(nonz-1, a[k-1])                        \\n                        ## NOTE: THIS WORKS, DON\\'T TOUCH!!!!\\n                        data = np.append((iLgn, iSig0, nonz-1), a[k-1])\\n                        #print(\"data =\",data)\\n                        sig.append(data)\\n                        ## NOTE: THIS WORKS, DON\\'T TOUCH!!!!\\n                        \\n                        #print(type(temp))\\n                        #temp += [a[k-1].tolist()]\\n                        #sig[iLgn][iSig0][nonz-1] = temp\\n                #if nLgn == 1:\\n                #    sig = np.vstack([sig, np.zeros_like(sig[0]), np.zeros_like(sig[0])])\\n                    #if nLgn == 1:\\n                    #    #print(\"nonz-1 =\", nonz-1)\\n                    #    data = np.zeros()\\n                    #    for i in range(1, 3):\\n                    #        data = np.append((i, 0, nonz-1), a[k-1])\\n                    #        sig.append(data)\\n                        #sig[0][iSig0][nonz-1].append(0)\\n                        #sig[1][iSig0][nonz-1].append(0)\\n    iRow += 1\\n# Convert lists to NumPy arrays for faster processing\\n\\nif nTemp == -1:\\n    #sigFinal = 0\\n    sigFinal = np.zeros(1)\\nelse:\\n    #sig = np.array(sig)\\n    sig   = np.stack(sig)   \\n    sigShape = sig.shape[0]\\n    z = int(sigShape/(nLgn*nSig0))\\n    sigFinal = sig[:, sig.shape[1]-1].reshape((nLgn, nSig0, z), order=\\'F\\')\\n    if nLgn == 1:\\n        # create two rows of zeros with shape (2, nSig0, sigShape)\\n        rows_of_zeros = np.zeros((2, nSig0, z))\\n        # stack original array and rows of zeros vertically\\n        sigFinal = np.vstack((sigFinal, rows_of_zeros))\\n\\nifrom = np.array(ifrom) \\nito   = np.array(ito) \\n\\nsigFinal.shape\\n'"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#================================\n",
    "# Testing different methods\n",
    "#================================\n",
    "mt = 16\n",
    "ntt = 3\n",
    "m = mmm\n",
    "#def extract_mf6(mt, ntt, m):\n",
    "iRow = 0 # row number               \n",
    "nTemp = -1 # number of temperatures\n",
    "# \"ifrom\" and \"ito\" will be both defined as empty lists\n",
    "# and bc depending on the CSV file, their sizes can change.\n",
    "# Later, they will be made into a NumPy arrays, bc it's \n",
    "# fast way to do scientific computing and can be easily \n",
    "# converted into other libraries, if need be.\n",
    "ifrom = [] # index of group 'from'\n",
    "ito = [] # index of group 'to'\n",
    "#sig = np.zeros((7, 6, 4636)) # <-- the best method currently but its basically cheating\n",
    "#sig = np.zeros([7, 6, 4636])\n",
    "\n",
    "# \n",
    "sig = []\n",
    "\n",
    "while m[iRow,6] != -1: # up to the end\n",
    "    if m[iRow,7] == 6 and m[iRow,8] == mt: # find the row with mf=6 & mt\n",
    "        if m[iRow,9] == 1: # this is the first line of mf=6 & mt: initialize\n",
    "            nonz = 0 # number of nonzeros\n",
    "            nLgn = int(m[iRow,2]) # number of Legendre components\n",
    "            nSig0 = int(m[iRow,3]) # number of sigma-zeros\n",
    "            print(\"nLgn =\", nLgn)\n",
    "\n",
    "            iRow += 1\n",
    "            nTemp += 1 # temperature index\n",
    "            #print(\"nTemp = \", nTemp)\n",
    "        ng2 = int(m[iRow,2]) # number of secondary positions\n",
    "        ig2lo = int(m[iRow,3]) # index to lowest nonzero group\n",
    "        nw = int(m[iRow,4]) # number of words to be read\n",
    "        ig = int(m[iRow,5]) # current group index\n",
    "        #print(\"ng2 =\", ng2, \"ig2lo =\", ig2lo)\n",
    "        iRow += 1     \n",
    "        a, iRowNew = extractNwords(nw, iRow, m) # extract nw words in vector a\n",
    "        iRow = iRowNew\n",
    "\n",
    "        #sig = np.zeros((nLgn, nSig0, nonz))\n",
    "        #sig = [[[0 for k in range(nonz)] for j in range(nSig0)] for i in range(nLgn)]\n",
    "\n",
    "        if nTemp == ntt:\n",
    "            #print(\"nTemp =\", nTemp,\n",
    "            #      \"ntt =\", ntt,\n",
    "            #      \"count =\", count)\n",
    "            #count += 1\n",
    "            k = nLgn*nSig0 # the first nLgn*nSig0 words are flux -- skip.\n",
    "            \n",
    "            #sig = [[[0 for k in range(nonz)] for j in range(nSig0)] for i in range(nLgn)]\n",
    "            for iTo in range(ig2lo, ig2lo+ng2-1):\n",
    "                nonz += 1\n",
    "                ifrom.append(ig)\n",
    "                ito.append(iTo)\n",
    "                #print(ig2lo)\n",
    "                #sig = np.zeros((nLgn, nSig0, nonz)) # Gives correct dimensions but only saves the last value\n",
    "                # sig = np.empty((nLgn, nSig0, nonz))\n",
    "                #sig = [[[0 for k in range(nonz)] for j in range(nSig0)] for i in range(nLgn)]\n",
    "                #sig = [[[] for _ in range(nSig0)] for _ in range(nLgn)]\n",
    "                for iSig0 in range(int(nSig0)):\n",
    "                    for iLgn in range(int(nLgn)):\n",
    "                        k += 1\n",
    "                        #print(\"iLgn =\", iLgn, \"iSig0 =\", iSig0, \"nonz-1 =\",nonz-1, \"a[k-1] =\",a[k-1] )\n",
    "                        #sig[iLgn][iSig0].append(a[k-1])\n",
    "                        #sig[iLgn][iSig0].insert(nonz-1, a[k-1])                        \n",
    "                        ## NOTE: THIS WORKS, DON'T TOUCH!!!!\n",
    "                        data = np.append((iLgn, iSig0, nonz-1), a[k-1])\n",
    "                        #print(\"data =\",data)\n",
    "                        sig.append(data)\n",
    "                        ## NOTE: THIS WORKS, DON'T TOUCH!!!!\n",
    "                        \n",
    "                        #print(type(temp))\n",
    "                        #temp += [a[k-1].tolist()]\n",
    "                        #sig[iLgn][iSig0][nonz-1] = temp\n",
    "                #if nLgn == 1:\n",
    "                #    sig = np.vstack([sig, np.zeros_like(sig[0]), np.zeros_like(sig[0])])\n",
    "                    #if nLgn == 1:\n",
    "                    #    #print(\"nonz-1 =\", nonz-1)\n",
    "                    #    data = np.zeros()\n",
    "                    #    for i in range(1, 3):\n",
    "                    #        data = np.append((i, 0, nonz-1), a[k-1])\n",
    "                    #        sig.append(data)\n",
    "                        #sig[0][iSig0][nonz-1].append(0)\n",
    "                        #sig[1][iSig0][nonz-1].append(0)\n",
    "    iRow += 1\n",
    "# Convert lists to NumPy arrays for faster processing\n",
    "\n",
    "if nTemp == -1:\n",
    "    #sigFinal = 0\n",
    "    sigFinal = np.zeros(1)\n",
    "else:\n",
    "    #sig = np.array(sig)\n",
    "    sig   = np.stack(sig)   \n",
    "    sigShape = sig.shape[0]\n",
    "    z = int(sigShape/(nLgn*nSig0))\n",
    "    sigFinal = sig[:, sig.shape[1]-1].reshape((nLgn, nSig0, z), order='F')\n",
    "    if nLgn == 1:\n",
    "        # create two rows of zeros with shape (2, nSig0, sigShape)\n",
    "        rows_of_zeros = np.zeros((2, nSig0, z))\n",
    "        # stack original array and rows of zeros vertically\n",
    "        sigFinal = np.vstack((sigFinal, rows_of_zeros))\n",
    "\n",
    "ifrom = np.array(ifrom) \n",
    "ito   = np.array(ito) \n",
    "\n",
    "sigFinal.shape\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# create original array of shape (1, 1, 1466)\\noriginal_array = np.random.rand(1, 1, 1466)\\n\\n# create two rows of zeros with shape (2, 1, 1466)\\nrows_of_zeros = np.zeros((2, 1, 1466))\\n\\n# stack original array and rows of zeros vertically\\nresult_array = np.vstack((original_array, rows_of_zeros))\\n\\n# print shape of result array\\nprint(result_array.shape)  # output: (3, 1, 1466)\\n'"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# create original array of shape (1, 1, 1466)\n",
    "original_array = np.random.rand(1, 1, 1466)\n",
    "\n",
    "# create two rows of zeros with shape (2, 1, 1466)\n",
    "rows_of_zeros = np.zeros((2, 1, 1466))\n",
    "\n",
    "# stack original array and rows of zeros vertically\n",
    "result_array = np.vstack((original_array, rows_of_zeros))\n",
    "\n",
    "# print shape of result array\n",
    "print(result_array.shape)  # output: (3, 1, 1466)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sigTest = []\\nfor i in range(2):\\n    data0Test = np.append((i), np.array([1,2,3]))\\n    #data1Test = np.append((1, iSig0, nonz-1), np.array([1,2,3]))\\n    sigTest.append(data0Test)\\nsigTest = np.stack(sigTest)\\nsigTest'"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"sigTest = []\n",
    "for i in range(2):\n",
    "    data0Test = np.append((i), np.array([1,2,3]))\n",
    "    #data1Test = np.append((1, iSig0, nonz-1), np.array([1,2,3]))\n",
    "    sigTest.append(data0Test)\n",
    "sigTest = np.stack(sigTest)\n",
    "sigTest\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# create a 2D array of shape (194712, 4)\\narr_2d = np.random.rand(194712)\\n\\n# calculate the value of z for a 3D array with shape (7, 6, z)\\nz = 778848 // (7*6*4)\\n\\n# reshape the array to a 3D array of shape (7, 6, z)\\narr_3d = arr_2d.reshape((7, 6, 4636))\\n\\n# print the shapes of the original and reshaped arrays\\nprint(\"Original shape:\", arr_2d.shape)\\nprint(\"Reshaped shape:\", arr_3d.shape)'"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# create a 2D array of shape (194712, 4)\n",
    "arr_2d = np.random.rand(194712)\n",
    "\n",
    "# calculate the value of z for a 3D array with shape (7, 6, z)\n",
    "z = 778848 // (7*6*4)\n",
    "\n",
    "# reshape the array to a 3D array of shape (7, 6, z)\n",
    "arr_3d = arr_2d.reshape((7, 6, 4636))\n",
    "\n",
    "# print the shapes of the original and reshaped arrays\n",
    "print(\"Original shape:\", arr_2d.shape)\n",
    "print(\"Reshaped shape:\", arr_3d.shape)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b = []\\nfor n in range(1, 3):\\n    data = np.full((2, 3), n)\\n    b.append(data)\\nb = np.stack(b)\\nprint(b)\\nprint(b.shape) # <- (2, 2, 3)'"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"b = []\n",
    "for n in range(1, 3):\n",
    "    data = np.full((2, 3), n)\n",
    "    b.append(data)\n",
    "b = np.stack(b)\n",
    "print(b)\n",
    "print(b.shape) # <- (2, 2, 3)\"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Start of convertCSVtoM()\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import data from H_001.CSV. "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[273], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m nameOnly \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39msplitext(csv_file)[\u001b[39m0\u001b[39m] \u001b[39m# find the name of the file without extension\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mImport data from \u001b[39m\u001b[39m{\u001b[39;00mnameOnly\u001b[39m}\u001b[39;00m\u001b[39m.CSV. \u001b[39m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m m \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mgenfromtxt(csv_file, delimiter\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m;\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m# load CSV file into matrix m\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m nRow \u001b[39m=\u001b[39m m\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m# number of rows\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/python310/lib64/python3.10/site-packages/numpy/lib/npyio.py:2227\u001b[0m, in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, ndmin, like)\u001b[0m\n\u001b[1;32m   2225\u001b[0m \u001b[39m# Parse each line\u001b[39;00m\n\u001b[1;32m   2226\u001b[0m \u001b[39mfor\u001b[39;00m (i, line) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(itertools\u001b[39m.\u001b[39mchain([first_line, ], fhd)):\n\u001b[0;32m-> 2227\u001b[0m     values \u001b[39m=\u001b[39m split_line(line)\n\u001b[1;32m   2228\u001b[0m     nbvalues \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(values)\n\u001b[1;32m   2229\u001b[0m     \u001b[39m# Skip an empty line\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/python310/lib64/python3.10/site-packages/numpy/lib/_iotools.py:226\u001b[0m, in \u001b[0;36mLineSplitter.__call__\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, line):\n\u001b[0;32m--> 226\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handyman(_decode_line(line, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding))\n",
      "File \u001b[0;32m~/envs/python310/lib64/python3.10/site-packages/numpy/lib/_iotools.py:205\u001b[0m, in \u001b[0;36mLineSplitter._delimited_splitter\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m line:\n\u001b[1;32m    204\u001b[0m     \u001b[39mreturn\u001b[39;00m []\n\u001b[0;32m--> 205\u001b[0m \u001b[39mreturn\u001b[39;00m line\u001b[39m.\u001b[39;49msplit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdelimiter)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "csv_files = [file for file in os.listdir('.') if file.endswith('.CSV')] # get a list of all CSV files in the current directory\n",
    "for csv_file in csv_files: # loop over all CSV files\n",
    "    nameOnly = os.path.splitext(csv_file)[0] # find the name of the file without extension\n",
    "    print(f\"Import data from {nameOnly}.CSV. \", end=\"\")\n",
    "    m = np.genfromtxt(csv_file, delimiter=';') # load CSV file into matrix m\n",
    "    print(\"Done.\")\n",
    "    nRow = m.shape[0] # number of rows\n",
    "\n",
    "    # Find number of temperatures and values of temperatures using mf=1 and mt=451\n",
    "    #temp = np.empty(4, dtype=np.float64) # index of group 'to'\n",
    "    nTemp = 0 # number of temperatures\n",
    "    temp = [] # vector of temperatures\n",
    "\n",
    "    for iRow in range(nRow):\n",
    "        if m[iRow,7] == 1 and m[iRow,8] == 451 and m[iRow,9] == 2:\n",
    "            nTemp += 1 # number of temperatures\n",
    "            temp.append(m[iRow,0]) # vector of temperatures)\n",
    "    temp = np.array(temp)\n",
    "\n",
    "    for iTemp in range(nTemp): # loop over temperatures\n",
    "        if temp[iTemp] < 1000:\n",
    "            isoName = f\"micro_{nameOnly}__{round(temp[iTemp])}K\" # name of the file with a temperature index\n",
    "        else:\n",
    "            isoName = f\"micro_{nameOnly}_{round(temp[iTemp])}K\" # name of the file with a temperature index\n",
    "\n",
    "        #if not os.path.exists(isoName + '.h5'): # if the corresponding HDF5 file does not exist\n",
    "        #    print(f\"check if HDF5 files for all temperatures are already available.\")\n",
    "    with h5py.File(isoName + '.h5', 'w') as hdf:\n",
    "        # Add important parameters for which the microscopic cross sections were generated\n",
    "        hdf.attrs['description'] = 'Python-based Neutron Transport Simulation'\n",
    "\n",
    "        # write the data to the HDF5 file\n",
    "        #hdf.create_dataset('atomic_weight', data=m[1, 1] * 1.008664916)\n",
    "        # write atomic_weight (amy) to the HDF5 file as metadata\n",
    "        hdf.attrs['atomic_weight'] = m[1, 1] * 1.008664916\n",
    "\n",
    "        # write group number to the HDF5 file as metadata\n",
    "        ng = int(421)\n",
    "        hdf.attrs['ng'] = ng\n",
    "        \n",
    "        # write temperature to the HDF5 file as data\n",
    "        #hdf.create_dataset('temperature', data=temp[iTemp])\n",
    "        hdf.attrs['temperature'] = temp[iTemp]\n",
    "\n",
    "        # extract and sigma-zeros and write into metadata\n",
    "        nSig0 = int(m[1, 3])\n",
    "        hdf.attrs['nSig0'] = nSig0\n",
    "\n",
    "        # extract the energy group boundaries \n",
    "        a = extractNwords(int(1 + nSig0 + (ng+1)), 3, m)\n",
    "        \n",
    "        # write energy group boundaries to the HDF5 file as a dataset\n",
    "        eg_G = hdf.create_group(\"en_G\")\n",
    "        eg_G.create_dataset('eg', data=a[0][int(1+nSig0) : int(2+nSig0+ng)])\n",
    "        #eg = a[0][int(1+nSig0) : int(2+nSig0+ng)]\n",
    "        #hdf.attrs['energy_group_boundaries'] = eg\n",
    "\n",
    "        # write sigma-zeros to the HDF5 file as a dataset\n",
    "        sig0_G = hdf.create_group(\"sig0_G\")\n",
    "        sig0_G.create_dataset('sig0', data=a[0][1 : int(2+nSig0-1)])\n",
    "        #sig0 = a[0][1 : int(2+nSig0-1)]\n",
    "        #hdf.attrs['sigma_zeros'] = sig0\n",
    "        \n",
    "        # write the number of sigma zeros to the HDF5 file as data\n",
    "        sig0_G.create_dataset('nSig0', data=nSig0)\n",
    "        #hdf.attrs['num_sigma_0'] = nSig0\n",
    "\n",
    "        #============================================================================================\n",
    "        # (n,gamma)\n",
    "        # The notation (n, gamma) represents a neutron capture reaction, where a neutron (n) is\n",
    "        # captured by a target nucleus and a gamma-ray (gamma) is emitted. This reaction is also\n",
    "        # sometimes referred to as radiative capture, as the gamma-ray emission indicates the release\n",
    "        # of energy from the system. The (n, gamma) reaction is an important process in nuclear \n",
    "        # astrophysics, as it is responsible for the creation of heavy elements in stars. It is also \n",
    "        # an important process in nuclear engineering, as it is used in neutron detectors and in the \n",
    "        # production of radioisotopes for medical and industrial applications.\n",
    "        # Extract mf=3 mt=102 (radiative capture cross sections)\n",
    "        #============================================================================================\n",
    "        print(f\"Convert {nameOnly}.CSV to {isoName}.h5: mf=3 mt=102 radiative capture\")\n",
    "        sigC = extract_mf3(102, iTemp, m)\n",
    "        nSig0C = sigC.shape[0]\n",
    "\n",
    "        sigC_G = hdf.create_group('sigC_G')\n",
    "        for iSig0 in range(nSig0C):\n",
    "            sigC_G.create_dataset(f\"sigC({iSig0},:)\", data=sigC[iSig0,0:ng])\n",
    "        if nSig0C == 1 and nSig0 > 1:\n",
    "            sigC_G.create_dataset('1:nSig0', data=sigC[0,0:ng])\n",
    "\n",
    "        #============================================================================================\n",
    "        # (n,alfa)\n",
    "        # The notation (n,) refers to a type of nuclear reaction where a neutron (n) is absorbed by \n",
    "        # a target nucleus, resulting in the emission of an alpha particle (). This is also known as \n",
    "        # an (n,) reaction. The alpha particle has a charge of +2 and a mass of 4, and is therefore \n",
    "        # a helium nucleus. (n,) reactions are important in nuclear physics and nuclear engineering, \n",
    "        # and they are used, for example, in the production of radioisotopes for medical and \n",
    "        # industrial applications.\n",
    "        #============================================================================================\n",
    "        print(f\"Convert {nameOnly}.CSV to {isoName}.h5: mf=3 mt=107 (n,alfa)\")\n",
    "        sigL = extract_mf3(107, iTemp, m)  # Extract mf=3 mt=107 (production of an alfa particle)\n",
    "        #if sigL.size == 0:\n",
    "        if (sigL == 0).all():\n",
    "            sigL = np.zeros((nSig0, ng))\n",
    "        else:\n",
    "            nSig0L = sigL.shape[0]\n",
    "            sigL_G = hdf.create_group(\"sigL_G\")\n",
    "            for iSig0 in range(nSig0L):\n",
    "                sigL_G.create_dataset(f\"sigL({iSig0},:)\", data=sigL[iSig0,0:ng])\n",
    "            if nSig0L == 1 and nSig0 > 1:\n",
    "                sigL = np.tile(sigL, (nSig0, 1))\n",
    "                sigL_G.create_dataset('sigL', data=sigL)\n",
    "\n",
    "        #============================================================================================\n",
    "        # (n,2n)\n",
    "        # The notation (n,2n) represents a type of nuclear reaction that occurs when a neutron (n) \n",
    "        # collides with a nucleus and causes it to emit two neutrons. This type of reaction is a type \n",
    "        # of neutron-induced reaction, and it is a common way for neutrons to be absorbed by a nucleus. \n",
    "        # In other words, a nucleus that absorbs a neutron in this type of reaction will usually emit \n",
    "        # two neutrons. The (n,2n) reaction can occur with a variety of target nuclei, and it is an \n",
    "        # important reaction in nuclear engineering and in the study of nuclear reactions.\n",
    "        #============================================================================================\n",
    "        print(f\"Convert {nameOnly}.CSV to {isoName}.h5: mf=6 mt=16 (n,2n) reaction\")\n",
    "        ifrom2, ito2, sig2 = extract_mf6(16, iTemp, m)  # Extract mf=6 mt=16 ((n,2n) matrix)\n",
    "        sig2_G = hdf.create_group('sig2_G')\n",
    "        #print(\"%% (n,2n) matrix for 1 Legendre component\")\n",
    "        #if ifrom2[0] == 0:\n",
    "        if (ifrom2 == 0).all():\n",
    "            isn2n = 0\n",
    "            sig2 = np.zeros((ng, ng))\n",
    "            sig2_G.create_dataset('sig2', data=sig2)\n",
    "        else:\n",
    "            isn2n = 1\n",
    "            sig2_G.create_dataset('ifrom2', data=ifrom2)\n",
    "            sig2_G.create_dataset('ito2', data=ito2)\n",
    "            sig2_sparse = sparse.coo_matrix((sig2[0, 0, :], (ifrom2-1, ito2-1)), shape=(ng, ng))\n",
    "            sig2_new = sig2_sparse.toarray()\n",
    "            sig2_G.create_dataset('sig2', data=sig2_new)\n",
    "        \n",
    "        #============================================================================================\n",
    "        # (n,n')\n",
    "        # The notation (n,n') represents a neutron inelastic scattering reaction, where a neutron is \n",
    "        # scattered by a nucleus, resulting in the emission of a different type of particle or gamma \n",
    "        # ray. In this notation, the \"n\" inside the parentheses represents the incident neutron, and \n",
    "        # the \"n'\" outside the parentheses represents the neutron that is scattered by the nucleus. \n",
    "        # This reaction is often used to study the properties of the target nucleus, such as its \n",
    "        # energy levels and excitation states.\n",
    "        #============================================================================================\n",
    "        igThresh = 95  # last group of thermal energy (e = 4 eV)\n",
    "        print(f'Convert {nameOnly}.CSV to {isoName}.h5: mf=6 mt=2 elastic scattering')\n",
    "        ifromE, itoE, sigE = extract_mf6(2, iTemp, m)  # Extract mf=6 mt=2 (elastic scattering matrix)\n",
    "        sigE_G = hdf.create_group('sigE_G')\n",
    "        nLgn = sigE.shape[0]-1  # nLgn = 6\n",
    "        sigS = [[np.zeros((ng, ng)) for _ in range(nSig0)] for _ in range(nLgn+1)]\n",
    "        for jLgn in range(nLgn + 1):    # 6 + 1\n",
    "            for iSig0 in range(nSig0):\n",
    "                for ii in range(len(ifromE)):\n",
    "                    if ifromE[ii] <= igThresh:\n",
    "                        sigE[jLgn, iSig0, ii] = 0         # 6(+1) 5(+1)\n",
    "                sigS[jLgn][iSig0] = sparse.coo_matrix((sigE[jLgn, iSig0, :]+1e-30, (ifromE-1, itoE-1)), shape=(ng, ng))\n",
    "                #print(sigS[0][0].toarray())    # To see the first cell\n",
    "                # Also just in case you are interesed in \n",
    "                # seeing the dimesions of sigS:\n",
    "                #for jLgn in range(nLgn + 1):\n",
    "                #    for iSig0 in range(nSig0):\n",
    "                #        print(f\"Shape of sigS[{jLgn}][{iSig0}]: {sigS[jLgn][iSig0].shape}\")\n",
    "        sigE_G.create_dataset('sigE', data=sigE)\n",
    "        \n",
    "        for ii in range(51, 92):\n",
    "            ifromI, itoI, sigI = extract_mf6(ii, iTemp, m) # Extract mf=6 mt=51 ... 91 (inelastic scattering matrix)\n",
    "            if len(ifromI) > 0 and ifromI[0] > 0:\n",
    "                print(f'Convert {nameOnly}.CSV to {isoName}.h5: mf=6 mt={ii:2d} inelastic scattering')\n",
    "                nLgn = sigI.shape[0]-1\n",
    "                for jLgn in range(nLgn+1):\n",
    "                    for iSig0 in range(nSig0):\n",
    "                        sigS[jLgn][iSig0] += sparse.coo_matrix((sigI[jLgn, 0]+1e-30, (ifromI-1, itoI-1)), shape=(ng, ng))\n",
    "\n",
    "        if isoName[0:11] == 'micro_H_001':\n",
    "            print(f'Convert {nameOnly}.CSV to {isoName}.h5: mf=6 mt=222 thermal scattering for hydrogen binded in water')\n",
    "            ifromI, itoI, sigI = extract_mf6(222, iTemp, m) # Extract mf=6 mt=222 thermal scattering for hydrogen binded in water\n",
    "        else:\n",
    "            print(f'Convert {nameOnly}.CSV to {isoName}.h5: mf=6 mt=221 free gas thermal scattering')\n",
    "            ifromI, itoI, sigI = extract_mf6(221, iTemp, m) # Extract mf=6 mt=221 free gas thermal scattering\n",
    "\n",
    "        nLgn = sigI.shape[0] - 1\n",
    "        for jLgn in range(nLgn + 1):\n",
    "            for iSig0 in range(nSig0):\n",
    "                sigS[jLgn][iSig0] += sparse.coo_matrix((sigI[jLgn, 0]+1e-30, (ifromI-1, itoI-1)), shape=(ng, ng))\n",
    "                #sigS[jLgn][iSig0] = sigS[jLgn][iSig0] + sparse.csr_matrix((sigI[jLgn, 0]+1e-30)*np.ones(len(ifromI)), (ifromI, itoI), shape=(int(ng), int(ng)))\n",
    "        \n",
    "        sigS_G = hdf.create_group(\"sigS_G\")\n",
    "        for jLgn in range(3):\n",
    "            for iSig0 in range(nSig0):\n",
    "                ifromS_, itoS_, sigS_ = find(sigS[jLgn][iSig0])\n",
    "                sigS_sparse = sparse.coo_matrix((sigS_, (ifromS_, itoS_)), shape=(ng, ng))\n",
    "                sigS_new = sigS_sparse.toarray()\n",
    "                sigS_G.create_dataset(f\"sigS({jLgn},{iSig0})\", data=sigS_new)\n",
    "        sigS_G.create_dataset(\"ifromS\", data=ifromS_)\n",
    "        sigS_G.create_dataset(\"itoS\", data=itoS_)\n",
    "\n",
    "        #============================================================================================\n",
    "        # (n,fis)\n",
    "        # The notation (n,fission) or (n,fis) refers to a nuclear reaction where a neutron (n) is \n",
    "        # absorbed by a target nucleus and the resulting compound nucleus undergoes fission, \n",
    "        # releasing a varying number of neutrons and other nuclear fragments (fission products). \n",
    "        # The reaction is often written as:\n",
    "        #   n + target nucleus  compound nucleus  fission products + neutrons + energy\n",
    "        # The number of neutrons released in a fission event can vary depending on the target nucleus \n",
    "        # and the incident neutron energy. This reaction is important in nuclear reactors where the \n",
    "        # released neutrons can initiate a chain reaction that generates energy.\n",
    "        #============================================================================================\n",
    "        print(f\"Convert {nameOnly}.CSV to {isoName}.h5: mf=3 mt=18 (fission cross sections)\")\n",
    "        sigF = extract_mf3(18, iTemp, m)  # Extract mf=3 mt=18 (fission cross sections)\n",
    "        sigF_G = hdf.create_group(\"sigF_G\")\n",
    "        nubar_G = hdf.create_group(\"nubar_G\")\n",
    "        chi_G = hdf.create_group(\"chi_G\")\n",
    "        if np.all(sigF == 0):\n",
    "            # fission cross sections (b)\n",
    "            sigF = np.zeros((nSig0, ng))\n",
    "            sigF_G.attrs['fissile'] = 0\n",
    "            sigF_G.create_dataset('sigF', data=sigF)\n",
    "            sigF_G.attrs['comment'] = '(n,fis)'\n",
    "            #=====================================================================\n",
    "            # nubar\n",
    "            # nubar is an important parameter in nuclear reactor physics and plays \n",
    "            # a crucial role in modelling the neutron transport. nubar is the \n",
    "            # average number of neutrons produced per fission event. It is an \n",
    "            # important quantity because it determines the multiplication factor \n",
    "            # (k-effective) of a nuclear reactor, which is a measure of whether \n",
    "            # the reactor is critical (k-effective = 1) or supercritical \n",
    "            # (k-effective > 1) or subcritical (k-effective < 1).\n",
    "            #=====================================================================\n",
    "            nubar = np.zeros((nSig0,ng))\n",
    "            nubar_G.create_dataset('nubar', data = nubar)\n",
    "            # fission spectrum\n",
    "            chi = np.zeros((nSig0,ng))\n",
    "            chi_G.create_dataset('chi', data=chi)\n",
    "        else:\n",
    "            print(f\"Convert {nameOnly}.CSV to {isoName}.h5: mf=3 mt=18 fission\")\n",
    "            sigF_G.attrs['fissile'] = 1\n",
    "            # fission cross sections (b) for {nSig0F} sigma-zero(s)\n",
    "            nSig0F = sigF.shape[0]\n",
    "            for iSig0 in range(nSig0F):\n",
    "                sigF_G.create_dataset(f\"sigF({iSig0},:)\", data=sigF[iSig0, 0:ng])\n",
    "\n",
    "            nubar = extract_mf3(452, iTemp, m)  # Extract mf=3 mt=452 (total nubar)\n",
    "            print(f\"Convert {nameOnly}.CSV to {isoName}.h5: mf=3 mt=452 total nubar\")\n",
    "\n",
    "            nSig0nu = nubar.shape[0]\n",
    "            for iSig0 in range(nSig0nu):\n",
    "                nubar_G.create_dataset(f\"nubar({iSig0},:)\", data=nubar[iSig0, 0:ng])\n",
    "\n",
    "            #============================================================================\n",
    "            # chi\n",
    "            # The chi function in the nuclear Boltzmann transport equation represents the \n",
    "            # distribution of neutrons produced by fission events. It describes the \n",
    "            # probability that a fission event will produce a neutron with a certain \n",
    "            # energy. Specifically, the chi function is defined as the product of two \n",
    "            # terms: the prompt fission neutron spectrum, which describes the energy \n",
    "            # distribution of neutrons emitted within a few microseconds of a fission \n",
    "            # event, and the delayed neutron precursor distribution, which describes the \n",
    "            # probability that a neutron precursor will decay and emit a neutron with a \n",
    "            # certain energy. The chi function is a crucial input parameter for nuclear \n",
    "            # reactor simulations, as it influences the behavior of the neutron \n",
    "            # population and the energy production in the reactor.\n",
    "            #============================================================================\n",
    "            print(f\"Convert {nameOnly}.CSV to {isoName}.h5: mf=6 mt=18 fission spectrum\")\n",
    "            iRow = 0\n",
    "            while not (m[iRow, 7] == 6 and m[iRow, 8] == 18): # find fission spectrum\n",
    "                iRow += 1\n",
    "            iRow += 1\n",
    "            ig2lo = int(m[iRow, 3]) # index to lowest nonzero group\n",
    "            nw = int(m[iRow, 4]) # number of words to be read\n",
    "            iRow += 1\n",
    "            a = extractNwords(nw, iRow, m)[0] # read nw words in vector a\n",
    "            chi = np.zeros(ng)\n",
    "            for iii in range(ig2lo-1):\n",
    "                chi[iii] = 0.0\n",
    "            for iii in range(nw):\n",
    "                chi[iii+ig2lo-1] = a[iii]\n",
    "            # fission spectrum\n",
    "            chi_G.create_dataset('chi', data=chi/np.sum(chi))\n",
    "\n",
    "        # Calculate total cross sections (note that mf=3 mt=1 does not include upscatters).\n",
    "        sigT_G = hdf.create_group(\"sigT_G\")\n",
    "        sigT = np.empty((nSig0,ng))\n",
    "        for iSig0 in range(nSig0):\n",
    "            # Compute the sum of the iSig0th row of sigS (using sparse.toarray() and np.sum())\n",
    "            sigS_sum = np.sum(sigS[0][iSig0].toarray(), axis=1)\n",
    "            # Add sigC(iSig0,:), sigF(iSig0,:), sigL(iSig0,:), and the sum to sigT(iSig0,:)\n",
    "            #sigT[iSig0,:] = sigC[iSig0] + sigF[iSig0] + sigL[iSig0] + sigS_sum\n",
    "            sigT[iSig0,:] = sigC[iSig0,:] + sigF[iSig0,:] + sigL[iSig0,:] + sigS_sum\n",
    "            if isn2n:\n",
    "                sigT[iSig0,:] += np.sum(sig2[0,0,:])\n",
    "            sigT_G.create_dataset(f\"sigT({iSig0},:)\", data=sigT[iSig0,:])\n",
    "                            \n",
    "\n",
    "        print(f\"Data for {isoName} saved to HDF5 file.\")\n",
    "        # File is automatically closed when the \"with\" block is exited\n",
    "        \n",
    "        #print(f'End of conversion for {nameOnly}.CSV to {isoName}.h5.')\n",
    "        #else:\n",
    "        #    print(f\"HDF5 file for {isoName} already exists.\")\n",
    "        # end of the if condition that checks if the file already exists\n",
    "    # end of the loop over temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.47896687 25.97896401 19.94901999  5.07182365  0.07314229]\n",
      "[ 3.47896531 25.97896384 19.94901999  5.07182365  0.07314229]\n",
      "[ 3.47895239 25.9789623  19.94901993  5.07182362  0.07314228]\n",
      "[ 3.47888164 25.97895056 19.94901941  5.07182343  0.07314222]\n",
      "[ 3.47879486 25.97892069 19.94901753  5.07182267  0.07314195]\n",
      "[ 3.47877441 25.97890795 19.94901635  5.07182212  0.07314174]\n"
     ]
    }
   ],
   "source": [
    "sigT = np.empty((nSig0,ng))\n",
    "for iSig0 in range(nSig0):\n",
    "    # Compute the sum of the iSig0th row of sigS (using sparse.toarray() and np.sum())\n",
    "    sigS_sum = np.sum(sigS[0][iSig0].toarray(), axis=1)\n",
    "    # Add sigC(iSig0,:), sigF(iSig0,:), sigL(iSig0,:), and the sum to sigT(iSig0,:)\n",
    "    #sigT[iSig0,:] = sigC[iSig0] + sigF[iSig0] + sigL[iSig0] + sigS_sum\n",
    "    sigT[iSig0,:] = sigC[iSig0,:] + sigF[iSig0,:] + sigL[iSig0,:] + sigS_sum\n",
    "    if isn2n:\n",
    "        sigT[iSig0,:] += np.sum(sig2[0,0,:])\n",
    "    print(sigT[iSig0,0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(421,)\n",
      "(6,)\n",
      "(421,)\n",
      "(421,)\n"
     ]
    }
   ],
   "source": [
    "sigF = extract_mf3(18, iTemp, m)  # Extract mf=3 mt=18 (fission cross sections)\n",
    "if np.all(sigF == 0):\n",
    "    # fission cross sections (b)\n",
    "            sigF = np.zeros((ng, nSig0))\n",
    "print(sigC[0,:].shape)  # (356,6)\n",
    "print(sigF[0,:].shape)  # (6,421)\n",
    "print(sigL[0,:].shape)  # (421,1)\n",
    "sigS_sum = np.sum(sigS[0][0].toarray(), axis=1)\n",
    "print(sigS_sum.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
