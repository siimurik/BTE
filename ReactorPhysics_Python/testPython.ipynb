{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse import find\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV data file into a Pandas DataFrame object\n",
    "data = pd.read_csv('B_010.CSV', delimiter=';', header=None)\n",
    "df = data.replace(r'^\\s*$', np.nan, regex=True).astype(float)   # df contains empty cells, \n",
    "                                                                # replace them with \"NaN\"\n",
    "# Print the updated DataFrame\n",
    "print(df.head(), \"\\n\", df.tail())   # First and last 5 rows."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Start of extractNwords()\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=======================================================\n",
    "The ENDF data within each record is often divided into \n",
    "fields or \"words\" of a fixed width. Therefore, this\n",
    "function plays an important role for \"extract_mf3\" and \n",
    "\"extract_mf6\" functions for extracting data from \n",
    "the ENDF file.\n",
    "-------------------------------------------------------\n",
    "INPUT:\n",
    "n - integer; the total number of words that need to be \n",
    "    extracted from the m matrix (whatever that means);\n",
    "iRow - integer; the index of the starting row of \n",
    "       the \"m\" matrix;\n",
    "m - 2D NumPy array; essentially a matrix containing \n",
    "    the data to be extracted.\n",
    "-------------------------------------------------------\n",
    "NOTE: Why \"m\" is a NumPy array, not a Pandas DataFrame?\n",
    "-------------------------------------------------------\n",
    "NumPy is usually much more forgiving if you are trying \n",
    "to access an element in an array. Essentially:\n",
    "\n",
    "        a[x,y] = a[x][y].\n",
    "\n",
    "For a Pandas DF, you would have to use .iloc[]\n",
    "which gets very bothersome, very quicly. Also,\n",
    "NumPy is just faster. Simple as that.\n",
    "-------------------------------------------------------\n",
    "OUTPUT:\n",
    "a - 1D NumPy array;\n",
    "iRowNew - integer; updated row number\n",
    "=======================================================\n",
    "\"\"\"\n",
    "def extractNwords(n, iRow, m):\n",
    "    k = 0   # counter for filling vector a\n",
    "    iRowNew = iRow\n",
    "    #a = np.empty((1,n), dtype=np.float64)\n",
    "    a = []\n",
    "    for ii in range(int(n/6)):  # read lines with 6 words each\n",
    "        for jj in range(6):\n",
    "            #a[0][k] = m[iRowNew][jj]\n",
    "            a.append(m[iRowNew][jj])\n",
    "            k += 1\n",
    "        iRowNew += 1\n",
    "\n",
    "    if (n - int(n/6)*6) == 0:   # check if there's a partial line with less than 6 words\n",
    "        iRowNew -= 1    # if yes, stay on the same row for next call to extractNwords()\n",
    "\n",
    "    for jj in range((n-int(n/6)*6)):  # read the last line with less than 6 words\n",
    "        #a[0][k] = m[iRowNew][jj]\n",
    "        a.append(m[iRowNew][jj])\n",
    "        k += 1\n",
    "\n",
    "    a = np.array(a)\n",
    "    return a, iRowNew"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Start of extract_mf3()\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "==========================================================\n",
    "In an ENDF type of file, MF 3 refers to the section that \n",
    "provides the cross-sections for outgoing neutrons produced \n",
    "by a particular reaction. Specifically, MF 3 contains the \n",
    "angular distributions and energy distributions of the \n",
    "outgoing neutrons, which are necessary for determining \n",
    "how the neutrons will interact with matter in subsequent \n",
    "calculations. The data in MF 3 is typically provided in \n",
    "tabular form as a function of incident neutron energy and \n",
    "scattering angle. This function extracts this data from\n",
    "the preprocessed CSV file.\n",
    "----------------------------------------------------------\n",
    "INPUT:\n",
    "mt  - integer; reaction\n",
    "ntt - integer; index for temperature value\n",
    "m - 2D NumPy array;\n",
    "----------------------------------------------------------\n",
    "OUTPUT:\n",
    "sig(nSig0, enGroup)- 2D NumPy array; where \"enGroup\" is \n",
    "the number of energy groups and \"nSig0\" is the the number \n",
    "of sigma-zeros.\n",
    "==========================================================\n",
    "\"\"\"\n",
    "\n",
    "def extract_mf3(mt, ntt, m):\n",
    "    nRow = m.shape[0]  # number of rows\n",
    "    nTemp = 0  # number of temperatures\n",
    "    iRowFound = 0\n",
    "    for iRow in range(nRow):\n",
    "        #if m.iloc[iRow, 7] == 3 and m.iloc[iRow, 8] == mt and m.iloc[iRow, 9] == 1:\n",
    "        if m[iRow, 7] == 3 and m[iRow, 8] == mt and m[iRow, 9] == 1:\n",
    "            # find the row with mf=3 and required mt\n",
    "            nTemp += 1  # number of temperatures\n",
    "            if nTemp-1 == ntt:  # NOTE: before it was nTemp == nt to ensure that\n",
    "                                # if you have four elements in a list, 4 would be\n",
    "                                # the last, but in Python, indexing starts from 0\n",
    "                                # so there is a bit of a dilemma here.\n",
    "                iRowFound = iRow + 1\n",
    "                break\n",
    "    if iRowFound > 0:  # there is mf=3 and required mt for this isotope\n",
    "        nSig0 = int(m[iRowFound-1, 3])  # number of sigma-zeros\n",
    "        nLgn = int(m[iRowFound-1, 2])  # number of Legendre components\n",
    "        iRow = iRowFound + 1\n",
    "        enGroup = int(m[2, 2])\n",
    "        sig = np.zeros((nSig0, enGroup))\n",
    "        while m[iRow, 7] == 3 and m[iRow, 8] == mt:\n",
    "            ig = int(m[iRow-1, 5])\n",
    "            a, iRowNew = extractNwords(nSig0 * nLgn * 2, iRow, m)\n",
    "            sig[0:nSig0, ig-1] = a[nSig0*nLgn:(nSig0*nLgn+nSig0)] # Benefits of using NumPy:\n",
    "            iRow = iRowNew + 2                                       # a[x,y] = a[x][y]\n",
    "    else:\n",
    "        sig = 0\n",
    "    return sig\n",
    "\n",
    "#====================================================\n",
    "# Example to check against MATLAB\n",
    "#mt = 102  # set the value of mt\n",
    "#iTemp = 1  # set the value of ntt\n",
    "#m = df.to_numpy()  # convert DataFrame to NumPy array\n",
    "#sigTest = extract_mf3(mt, 3, m)  # apply the function to the numpy array\n",
    "#sigTest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Start of extract_mf6()\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "==============================================================\n",
    "NOTE: Undefined list method\n",
    "MF 6 stands for \"Cross Sections\" in an ENDF (Evaluated Nuclear\n",
    "Data File) type of file. This section contains the evaluated \n",
    "cross-section data, such as the neutron-induced reaction cross \n",
    "sections, as a function of incident neutron energy. The cross-\n",
    "section data may be provided in tabular or in resonance format. \n",
    "Additionally, the section may also contain the angular distri-\n",
    "butions, energy-angle distributions, or other related data. \n",
    "This information is essential for the calculation of the neut-\n",
    "ron transport in nuclear reactors and other applications.\n",
    "--------------------------------------------------------------\n",
    "MAIN TASKS:\n",
    " 1. Initialize variables (iRow, nTemp, ifrom, ito, sig)\n",
    " 2. Loop through each row of the ENDF file (until the end is \n",
    " reached)\n",
    " 3. If the current row contains the MF/MT we are looking for, \n",
    " extract the data\n",
    " 4. Store the data in a list (sig)\n",
    "--------------------------------------------------------------\n",
    "INPUT:\n",
    "mt  - integer; reaction;\n",
    "ntt - integer; index for temperature value;\n",
    "m - 2D NumPy array; contains the ENDF data\n",
    "--------------------------------------------------------------\n",
    "OUTPUT:\n",
    "ifrom - 1D NumPy array;\n",
    "ito   - 1D NumPy array;\n",
    "sig   - 3D NumPy array;\n",
    "==============================================================\n",
    "\"\"\"\n",
    "def extract_mf6(mt, ntt, m):\n",
    "    iRow = 0 # row number               \n",
    "    nTemp = 0 # number of temperatures\n",
    "    # \"ifrom\" and \"ito\" will be both defined as empty lists\n",
    "    # and bc depending on the CSV file, their sizes can change.\n",
    "    # Later, they will be made into a NumPy arrays, bc it's \n",
    "    # fast way to do scientific computing and can be easily \n",
    "    # converted into other libraries, if need be.\n",
    "    ifrom = [] # index of group 'from'\n",
    "    ito = [] # index of group 'to'\n",
    "    #sig = [] # list to store the data\n",
    "    nSig0 = None\n",
    "    nLgn = None\n",
    "\n",
    "    while m[iRow,6] != -1: # up to the end\n",
    "        if m[iRow,7] == 6 and m[iRow,8] == mt: # find the row with mf=6 & mt\n",
    "            if m[iRow,9] == 1: # this is the first line of mf=6 & mt: initialize\n",
    "                nonz = 0 # number of nonzeros\n",
    "                nLgn = int(m[iRow,2]) # number of Legendre components\n",
    "                nSig0 = int(m[iRow,3]) # number of sigma-zeros\n",
    "\n",
    "                # Prolly the most confusing command in the entire function.\n",
    "                # \"sig\" is a bit more tricky compared to \"ifrom\" and \"ito\".\n",
    "                # Essentially, it is still an undefined list, with undefinded \n",
    "                # lists inside it, but all it does is set up an empty 3D matrix.\n",
    "                sig = [[[] for _ in range(nSig0)] for _ in range(nLgn)] # initialize sig\n",
    "\n",
    "                iRow += 1\n",
    "                nTemp += 1 # temperature index\n",
    "            ng2 = int(m[iRow,2]) # number of secondary positions\n",
    "            ig2lo = int(m[iRow,3]) # index to lowest nonzero group\n",
    "            nw = int(m[iRow,4]) # number of words to be read\n",
    "            ig = int(m[iRow,5]) # current group index\n",
    "\n",
    "            iRow += 1     \n",
    "            a, iRowNew = extractNwords(nw, iRow, m) # extract nw words in vector a\n",
    "            iRow = iRowNew\n",
    "\n",
    "            if nTemp-1 == ntt:  # if you use nTemp == ntt, it uses the MATLAB indexing\n",
    "                                # starting from 1\n",
    "                k = nLgn*nSig0 # the first nLgn*nSig0 words are flux -- skip.\n",
    "                for iTo in range(ig2lo, ig2lo+ng2-1):\n",
    "                    nonz += 1\n",
    "                    ifrom.append(ig)\n",
    "                    ito.append(iTo)\n",
    "                    for iSig0 in range(1, int(nSig0+1)):\n",
    "                        for iLgn in range(1, int(nLgn+1)):\n",
    "                            k += 1\n",
    "                            sig[iLgn-1][iSig0-1].append(a[k-1])\n",
    "                        if nLgn == 1:\n",
    "                            sig[1][iSig0-1].append(0)\n",
    "                            sig[2][iSig0-1].append(0)\n",
    "        iRow += 1\n",
    "    if nTemp == 0:\n",
    "        sig = 0\n",
    "\n",
    "    # Convert lists to NumPy arrays for faster processing\n",
    "    ifrom = np.array(ifrom) \n",
    "    ito   = np.array(ito) \n",
    "    sig   = np.array(sig)   # Make that list within lists into a 3D Matrix\n",
    "\n",
    "    # Return the extracted data as well as the indices\n",
    "    return ifrom, ito, sig\n",
    "\n",
    "#=====================================================\n",
    "# Testing/Exapmple\n",
    "#for iTemp in range(nTemp+1):\n",
    "m = df.to_numpy()\n",
    "ifromE, itoE, sigE = extract_mf6(2, 3, m)\n",
    "\n",
    "np.shape(sigE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================\n",
    "# Testing different methods\n",
    "#================================\n",
    "mt = 2\n",
    "ntt = 1\n",
    "m = df.to_numpy()\n",
    "#def extract_mf6(mt, ntt, m):\n",
    "iRow = 0 # row number               \n",
    "nTemp = 0 # number of temperatures\n",
    "# \"ifrom\" and \"ito\" will be both defined as empty lists\n",
    "# and bc depending on the CSV file, their sizes can change.\n",
    "# Later, they will be made into a NumPy arrays, bc it's \n",
    "# fast way to do scientific computing and can be easily \n",
    "# converted into other libraries, if need be.\n",
    "ifrom = [] # index of group 'from'\n",
    "ito = [] # index of group 'to'\n",
    "#sig = np.zeros((7, 6, 4636)) # <-- the best method currently but its basically cheating\n",
    "nSig0 = None\n",
    "nLgn = None\n",
    "#count = 0\n",
    "while m[iRow,6] != -1: # up to the end\n",
    "    if m[iRow,7] == 6 and m[iRow,8] == mt: # find the row with mf=6 & mt\n",
    "        if m[iRow,9] == 1: # this is the first line of mf=6 & mt: initialize\n",
    "            nonz = 0 # number of nonzeros\n",
    "            nLgn = int(m[iRow,2]) # number of Legendre components\n",
    "            nSig0 = int(m[iRow,3]) # number of sigma-zeros\n",
    "            # Prolly the most confusing part in the entire function.\n",
    "            # \"sig\" is a bit more tricky compared to \"ifrom\" and \"ito\".\n",
    "            # Essentially, it is still an undefined list, with undefinded \n",
    "            # lists inside it, but all it does is set up an empty 3D matrix.\n",
    "            # NOTE: all the failed attempts\n",
    "            #sig = [[[] for _ in range(nSig0)] for _ in range(nLgn)] # initialize sig\n",
    "            #sig = [[np.zeros((1, nonz)) for _ in range(nSig0)] for _ in range(nLgn+1)]\n",
    "            #sig = np.zeros((nLgn, nSig0, nonz))\n",
    "            #sig = np.array([[[] for _ in range(nSig0)] for _ in range(nLgn)])\n",
    "            #sig = np.zeros((nLgn, nSig0, nonz))\n",
    "            #sig = [[[0 for k in range(nonz)] for j in range(nSig0)] for i in range(nLgn)]\n",
    "            iRow += 1\n",
    "            nTemp += 1 # temperature index\n",
    "            #print(\"nTemp =\", nTemp)\n",
    "        ng2 = int(m[iRow,2]) # number of secondary positions\n",
    "        ig2lo = int(m[iRow,3]) # index to lowest nonzero group\n",
    "        nw = int(m[iRow,4]) # number of words to be read\n",
    "        ig = int(m[iRow,5]) # current group index\n",
    "\n",
    "        iRow += 1     \n",
    "        a, iRowNew = extractNwords(nw, iRow, m) # extract nw words in vector a\n",
    "        iRow = iRowNew\n",
    "\n",
    "        #sig = np.zeros((nLgn, nSig0, nonz))\n",
    "        #sig = [[[0 for k in range(nonz)] for j in range(nSig0)] for i in range(nLgn)]\n",
    "        if nTemp == ntt:\n",
    "            #print(\"nTemp =\", nTemp,\n",
    "            #      \"ntt =\", ntt,\n",
    "            #      \"count =\", count)\n",
    "            #count += 1\n",
    "            k = nLgn*nSig0 # the first nLgn*nSig0 words are flux -- skip.\n",
    "            #sig = [[[0 for k in range(nonz)] for j in range(nSig0)] for i in range(nLgn)]\n",
    "            for iTo in range(ig2lo, ig2lo+ng2-1):\n",
    "                nonz += 1\n",
    "                ifrom.append(ig)\n",
    "                ito.append(iTo)\n",
    "                # sig = np.zeros((nLgn, nSig0, nonz)) # Gives correct dimensions but only saves the last value\n",
    "                # sig = np.empty((nLgn, nSig0, nonz))\n",
    "                #sig = [[[0 for k in range(nonz)] for j in range(nSig0)] for i in range(nLgn)]\n",
    "                #sig = [[[] for _ in range(nSig0)] for _ in range(nLgn)]\n",
    "                for iSig0 in range(int(nSig0)):\n",
    "                    for iLgn in range(int(nLgn)):\n",
    "                        k += 1\n",
    "                        #print(\"iLgn =\", iLgn, \"iSig0 =\", iSig0, \"nonz-1 =\",nonz-1, \"a[k-1] =\",a[k-1] )\n",
    "                        #sig[iLgn][iSig0].append(a[k-1])\n",
    "                        #sig[iLgn][iSig0][nonz-1].append(a[k-1])\n",
    "                        #sig[iLgn][iSig0][nonz-1] = a[k-1]\n",
    "                        temp = sig[iLgn][iSig0][nonz-1].tolist()\n",
    "                        print(type(temp))\n",
    "                        #temp += [a[k-1].tolist()]\n",
    "                        #sig[iLgn][iSig0][nonz-1] = temp\n",
    "                    if nLgn == 1:\n",
    "                        sig[1][iSig0][nonz-1].append(0)\n",
    "                        sig[2][iSig0][nonz-1].append(0)\n",
    "    iRow += 1\n",
    "if nTemp == 0:\n",
    "    sig = 0\n",
    "\n",
    "# Convert lists to NumPy arrays for faster processing\n",
    "ifrom = np.array(ifrom) \n",
    "ito   = np.array(ito) \n",
    "sig   = np.array(sig)   # Make that list within lists into a 3D Matrix\n",
    "sig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, iRowNew = extractNwords(nw, iRow, m) # extract nw words in vector a\n",
    "type(a)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Start of convertCSVtoM()\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = [file for file in os.listdir('.') if file.endswith('.CSV')] # get a list of all CSV files in the current directory\n",
    "for csv_file in csv_files: # loop over all CSV files\n",
    "    nameOnly = os.path.splitext(csv_file)[0] # find the name of the file without extension\n",
    "    print(f\"Import data for {nameOnly} and check if Matlab files for all temperatures are already available. \", end=\"\")\n",
    "    m = np.genfromtxt(csv_file, delimiter=';') # load CSV file into matrix m\n",
    "    print(\"Done.\")\n",
    "    nRow = m.shape[0] # number of rows\n",
    "\n",
    "    # Find number of temperatures and values of temperatures using mf=1 and mt=451\n",
    "    #temp = np.empty(4, dtype=np.float64) # index of group 'to'\n",
    "    nTemp = 0 # number of temperatures\n",
    "    temp = [] # vector of temperatures\n",
    "\n",
    "    for iRow in range(nRow):\n",
    "        if m[iRow,7] == 1 and m[iRow,8] == 451 and m[iRow,9] == 2:\n",
    "            nTemp += 1 # number of temperatures\n",
    "            temp.append(m[iRow,0]) # vector of temperatures)\n",
    "    temp = np.array(temp)\n",
    "\n",
    "    for iTemp in range(nTemp): # loop over temperatures\n",
    "        if temp[iTemp] < 1000:\n",
    "            isoName = f\"micro_{nameOnly}__{round(temp[iTemp])}K\" # name of the file with a temperature index\n",
    "        else:\n",
    "            isoName = f\"micro_{nameOnly}_{round(temp[iTemp])}K\" # name of the file with a temperature index\n",
    "\n",
    "#if not os.path.exists(isoName + '.h5'): # if the corresponding HDF5 file does not exist\n",
    "\n",
    "        with h5py.File(isoName + '.h5', 'w') as hdf:\n",
    "            # Add important parameters for which the microscopic cross sections were generated\n",
    "            hdf.attrs['description'] = 'Python-based Neutron Transport Simulation'\n",
    "\n",
    "            # write the data to the HDF5 file\n",
    "            #hdf.create_dataset('atomic_weight', data=m[1, 1] * 1.008664916)\n",
    "            # write atomic_weight (amy) to the HDF5 file as metadata\n",
    "            hdf.attrs['atomic_weight'] = m[1, 1] * 1.008664916\n",
    "\n",
    "            # write group number to the HDF5 file as metadata\n",
    "            ng = int(421)\n",
    "            hdf.attrs['ng'] = ng\n",
    "            \n",
    "            # extract the energy group boundaries and sigma-zeros\n",
    "            nSig0 = int(m[1, 3])\n",
    "            a = extractNwords(int(1 + nSig0 + (ng+1)), 3, m)\n",
    "            \n",
    "            # write energy group boundaries to the HDF5 file as a dataset\n",
    "            hdf.create_dataset('energy_group_boundaries', data=a[0][int(1+nSig0) : int(2+nSig0+ng)])\n",
    "            #eg = a[0][int(1+nSig0) : int(2+nSig0+ng)]\n",
    "            #hdf.attrs['energy_group_boundaries'] = eg\n",
    "\n",
    "            # write sigma-zeros to the HDF5 file as a dataset\n",
    "            hdf.create_dataset('sigma_zeros', data=a[0][1 : int(2+nSig0-1)])\n",
    "            #sig0 = a[0][1 : int(2+nSig0-1)]\n",
    "            #hdf.attrs['sigma_zeros'] = sig0\n",
    "            \n",
    "            # write the number of sigma zeros to the HDF5 file as data\n",
    "            hdf.create_dataset('num_sigma_0', data=nSig0)\n",
    "            #hdf.attrs['num_sigma_0'] = nSig0\n",
    "\n",
    "            # write temperature to the HDF5 file as data\n",
    "            hdf.create_dataset('temperature', data=temp[iTemp])\n",
    "            #hdf.attrs['temperature'] = temp[iTemp]\n",
    "            \n",
    "            # (n,gamma)\n",
    "            # Extract mf=3 mt=102 (radiative capture cross sections)\n",
    "            print(f\"Convert {nameOnly}.CSV to {isoName}.m: mf=3 mt=102 radiative capture\")\n",
    "            sigC = extract_mf3(102, iTemp, m)\n",
    "            nSig0C = sigC.shape[0]\n",
    "            #nSig0C = 1\n",
    "\n",
    "            sigC_G = hdf.create_group('sigC_G')\n",
    "            for iSig0 in range(nSig0C):\n",
    "                sigC_G.create_dataset(f\"sigC({iSig0},:)\", data=sigC[iSig0,0:ng])\n",
    "            if nSig0C == 1 and nSig0 > 1:\n",
    "                sigC_G.create_dataset('1:nSig0', data=sigC[0,0:ng])\n",
    "            \n",
    "            #========================================================================================\n",
    "            # (n,alfa)\n",
    "            print(f\"Convert {nameOnly}.CSV to {isoName}.m: mf=3 mt=107 (n,alfa)\")\n",
    "            sigL = extract_mf3(107, iTemp, m)  # Extract mf=3 mt=107 (production of an alfa particle)\n",
    "            #if sigL.size == 0:\n",
    "            if (sigL == 0).all():\n",
    "                sigL = np.zeros((nSig0, ng))\n",
    "            else:\n",
    "                nSig0L = sigL.shape[0]\n",
    "                sigL_G = hdf.create_group(\"sigL_G\")\n",
    "                for iSig0 in range(nSig0L):\n",
    "                    sigL_G.create_dataset(f\"sigL({iSig0},:)\", data=sigL[iSig0,0:ng])\n",
    "                if nSig0L == 1 and nSig0 > 1:\n",
    "                    sigL = np.tile(sigL, (nSig0, 1))\n",
    "                    sigL_G.create_dataset('sigL', data=sigL)\n",
    "\n",
    "            # (n,2n)\n",
    "            print(f\"Convert {nameOnly}.CSV to {isoName}.m: mf=6 mt=16 (n,2n) reaction\")\n",
    "            ifrom2, ito2, sig2 = extract_mf6(16, iTemp, m)  # Extract mf=6 mt=16 ((n,2n) matrix)\n",
    "            sig2_G = hdf.create_group('sig2_G')\n",
    "            #print(\"%% (n,2n) matrix for 1 Legendre component\")\n",
    "            #if ifrom2[0] == 0:\n",
    "            if (ifrom2 == 0).all():\n",
    "                isn2n = 0\n",
    "                sig2 = np.zeros((ng, ng))\n",
    "                sig2_G.create_dataset('sig2', data=sig2)\n",
    "            else:\n",
    "                isn2n = 1\n",
    "                sig2_G.create_dataset('ifrom2', data=ifrom2)\n",
    "                sig2_G.create_dataset('ito2', data=ito2)\n",
    "                sig2_sparse = sparse.coo_matrix((sig2[0, 0, :], (ifrom2-1, ito2-1)), shape=(ng, ng))\n",
    "                sig2_new = sig2_sparse.toarray()\n",
    "                sig2_G.create_dataset('sig2', data=sig2_new)\n",
    "                \n",
    "            # (n,n')\n",
    "            igThresh = 95  # last group of thermal energy (e = 4 eV)\n",
    "\n",
    "            print(f'Convert {nameOnly}.CSV to {isoName}.m: mf=6 mt=2 elastic scattering')\n",
    "            ifromE, itoE, sigE = extract_mf6(2, iTemp, m)  # Extract mf=6 mt=2 (elastic scattering matrix)\n",
    "            sigE_G = hdf.create_group('sigE_G')\n",
    "            nLgn = sigE.shape[0]-1  # nLgn = 6\n",
    "            sigS = [[np.zeros((ng, ng)) for _ in range(nSig0)] for _ in range(nLgn+1)]\n",
    "            for jLgn in range(nLgn + 1):    # 6 + 1\n",
    "                for iSig0 in range(nSig0):\n",
    "                    for ii in range(len(ifromE)):\n",
    "                        if ifromE[ii] <= igThresh:\n",
    "                            sigE[jLgn, iSig0, ii] = 0         # 6(+1) 5(+1)\n",
    "                    sigS[jLgn][iSig0] = sparse.coo_matrix((sigE[jLgn, iSig0, :]+1e-30, (ifromE-1, itoE-1)), shape=(ng, ng))\n",
    "                    #print(sigS[0][0].toarray())    # To see the first cell\n",
    "                    # Also just in case you are interesed in \n",
    "                    # seeing the dimesions of sigS:\n",
    "                    #for jLgn in range(nLgn + 1):\n",
    "                    #    for iSig0 in range(nSig0):\n",
    "                    #        print(f\"Shape of sigS[{jLgn}][{iSig0}]: {sigS[jLgn][iSig0].shape}\")\n",
    "            sigE_G.create_dataset('sigE', data=sigE)\n",
    "            \n",
    "            for ii in range(51, 92):\n",
    "                ifromI, itoI, sigI = extract_mf6(ii, iTemp, m) # Extract mf=6 mt=51 ... 91 (inelastic scattering matrix)\n",
    "                if len(ifromI) > 0 and ifromI[0] > 0:\n",
    "                    print(f'Convert {nameOnly}.CSV to {isoName}.h5: mf=6 mt={ii:2d} inelastic scattering')\n",
    "                    nLgn = sigI.shape[0]-1\n",
    "                    for jLgn in range(nLgn+1):\n",
    "                        for iSig0 in range(nSig0):\n",
    "                            sigS[jLgn][iSig0] += sparse.coo_matrix((sigI[jLgn, 0]+1e-30, (ifromI-1, itoI-1)), shape=(ng, ng))\n",
    "\n",
    "            if isoName[0:11] == 'micro_H_001':\n",
    "                print(f'Convert {nameOnly}.CSV to {isoName}.h5: mf=6 mt=222 thermal scattering for hydrogen binded in water')\n",
    "                ifromI, itoI, sigI = extract_mf6(222, iTemp, m) # Extract mf=6 mt=222 thermal scattering for hydrogen binded in water\n",
    "            else:\n",
    "                print(f'Convert {nameOnly}.CSV to {isoName}.m: mf=6 mt=221 free gas thermal scattering')\n",
    "                ifromI, itoI, sigI = extract_mf6(221, iTemp, m) # Extract mf=6 mt=221 free gas thermal scattering\n",
    "\n",
    "            nLgn = sigI.shape[0] - 1\n",
    "            for jLgn in range(nLgn + 1):\n",
    "                for iSig0 in range(nSig0):\n",
    "                    sigS[jLgn][iSig0] += sparse.coo_matrix((sigI[jLgn, 0]+1e-30, (ifromI-1, itoI-1)), shape=(ng, ng))\n",
    "                    #sigS[jLgn][iSig0] = sigS[jLgn][iSig0] + sparse.csr_matrix((sigI[jLgn, 0]+1e-30)*np.ones(len(ifromI)), (ifromI, itoI), shape=(int(ng), int(ng)))\n",
    "            \n",
    "            sigS_G = hdf.create_group(\"sigS_G\")\n",
    "            for jLgn in range(3):\n",
    "                for iSig0 in range(nSig0):\n",
    "                    ifromS_, itoS_, sigS_ = find(sigS[jLgn][iSig0])\n",
    "                    sigS_sparse = sparse.coo_matrix((sigS_, (ifromS_, itoS_)), shape=(ng, ng))\n",
    "                    sigS_new = sigS_sparse.toarray()\n",
    "                    sigS_G.create_dataset(f\"sigS({jLgn},{iSig0})\", data=sigS_new)\n",
    "            sigS_G.create_dataset(\"ifromS\", data=ifromS_)\n",
    "            sigS_G.create_dataset(\"itoS\", data=itoS_)\n",
    "\n",
    "            # (n,fis)\n",
    "            print(f\"Convert {nameOnly}.CSV to {isoName}.h5: mf=3 mt=18 (fission cross sections)\")\n",
    "            sigF = extract_mf3(18, iTemp, m)  # Extract mf=3 mt=18 (fission cross sections)\n",
    "            sigF_G = hdf.create_group(\"sigF_G\")\n",
    "            nubar_G = hdf.create_group(\"nubar_G\")\n",
    "            chi_G = hdf.create_group(\"chi_G\")\n",
    "            if np.all(sigF == 0):\n",
    "                # fission cross sections (b)\n",
    "                sigF = np.zeros((nSig0, ng))\n",
    "                sigF_G.attrs['fissile'] = 0\n",
    "                sigF_G.create_dataset('sigF', data=sigF)\n",
    "                sigF_G.attrs['comment'] = '(n,fis)'\n",
    "                # nubar?\n",
    "                nubar = np.zeros((nSig0,ng))\n",
    "                nubar_G.create_dataset('nubar', data = nubar)\n",
    "                # fission spectrum\n",
    "                chi = np.zeros((nSig0,ng))\n",
    "                chi_G.create_dataset('chi', data=chi)\n",
    "            else:\n",
    "                print(f\"Convert {nameOnly}.CSV to {isoName}.h5: mf=3 mt=18 fission\")\n",
    "                sigF_G.attrs['fissile'] = 1\n",
    "                # fission cross sections (b) for {nSig0F} sigma-zero(s)\n",
    "                nSig0F = sigF.shape[0]\n",
    "                for iSig0 in range(nSig0F):\n",
    "                    sigF_G.create_dataset(f\"sigF({iSig0},:)\", data=sigF[iSig0, 0:ng])\n",
    "\n",
    "                nubar = extract_mf3(452, iTemp, m)  # Extract mf=3 mt=452 (total nubar)\n",
    "                print(f\"Convert {nameOnly}.CSV to {isoName}.m: mf=3 mt=452 total nubar\")\n",
    "\n",
    "                nSig0nu = nubar.shape[0]\n",
    "                for iSig0 in range(nSig0nu):\n",
    "                    nubar_G.create_dataset(f\"nubar({iSig0},:)\", data=nubar[iSig0, 0:ng])\n",
    "\n",
    "                # chi\n",
    "                print(f\"Convert {nameOnly}.CSV to {isoName}.h5: mf=6 mt=18 fission spectrum\")\n",
    "                iRow = 0\n",
    "                while not (m[iRow, 7] == 6 and m[iRow, 8] == 18): # find fission spectrum\n",
    "                    iRow += 1\n",
    "                iRow += 1\n",
    "                ig2lo = m[iRow, 3] # index to lowest nonzero group\n",
    "                nw = m[iRow, 4] # number of words to be read\n",
    "                iRow += 1\n",
    "                a = extractNwords(nw, iRow, m)[0] # read nw words in vector a\n",
    "                chi = np.zeros(ng)\n",
    "                for iii in range(ig2lo-1):\n",
    "                    chi[iii] = 0.0\n",
    "                for iii in range(nw):\n",
    "                    chi[iii+ig2lo-1] = a[iii]\n",
    "                # fission spectrum\n",
    "                chi_G.create_dataset('chi', data=chi/np.sum(chi))\n",
    "\n",
    "            # Calculate total cross sections (note that mf=3 mt=1 does not include upscatters).\n",
    "            sigT_G = hdf.create_group(\"sigT_G\")\n",
    "            sigT = np.empty((nSig0,ng))\n",
    "            for iSig0 in range(nSig0):\n",
    "                # Compute the sum of the iSig0th row of sigS (using sparse.toarray() and np.sum())\n",
    "                sigS_sum = np.sum(sigS[0][iSig0].toarray(), axis=1)\n",
    "                # Add sigC(iSig0,:), sigF(iSig0,:), sigL(iSig0,:), and the sum to sigT(iSig0,:)\n",
    "                #sigT[iSig0,:] = sigC[iSig0] + sigF[iSig0] + sigL[iSig0] + sigS_sum\n",
    "                sigT[iSig0,:] = sigC[iSig0,:] + sigF[iSig0,:] + sigL[iSig0,:] + sigS_sum\n",
    "                if isn2n:\n",
    "                    sigT += np.sum(sig2[0,0,:], axis=1)\n",
    "                sigT_G.create_dataset(f\"sigT({iSig0},:)\", data=sigT)\n",
    "        \n",
    "\n",
    "            print(f\"Data for {isoName} saved to HDF5 file.\")\n",
    "            # File is automatically closed when the \"with\" block is exited\n",
    "    \n",
    "    # end of the loop over temperatures\n",
    "#else:\n",
    "#    print(f\"HDF5 file for {isoName} already exists.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifromE, itoE, sigE = extract_mf6(2, iTemp, m)\n",
    "sigE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
